{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.sparse import csc_matrix, csr_matrix\n",
    "import pickle\n",
    "import pretty_midi\n",
    "import sys\n",
    "import copy\n",
    "from collections import namedtuple\n",
    "import timeit\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'src.ml_classes' from 'C:\\\\Users\\\\Andrew\\\\Documents\\\\mlprojects\\\\781-piano-autoencoder\\\\src\\\\ml_classes.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import modules, including a reload statement so that they can be reimported after a change to the methods \n",
    "import src.midi_utils as midi_utils\n",
    "reload(midi_utils)\n",
    "\n",
    "import src.data as data\n",
    "reload(data)\n",
    "\n",
    "import src.models as models\n",
    "reload(models)\n",
    "\n",
    "import src.ml_classes as ml_classes\n",
    "reload(ml_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26732860000265646\n",
      "0.14455119999911403\n"
     ]
    }
   ],
   "source": [
    "# two ways of transposing if they are integers indicating pitch, but dimensions are unknown\n",
    "int_transpose = np.vectorize(lambda x: min(max(x + semitones, 0), 87))\n",
    "def int_transpose1():\n",
    "    semitones = 2\n",
    "    b = np.array([[1,2,3],[3,4,5]])\n",
    "    b = int_transpose(b)\n",
    "\n",
    "# or like this:\n",
    "def int_transpose2():\n",
    "    semitones = 2\n",
    "    b = np.array([[1,2,3],[3,4,5]])\n",
    "    for idx,value in np.ndenumerate(b):\n",
    "        b[idx] = min(max(value + semitones, 0), 87)\n",
    "    \n",
    "print(timeit.timeit(int_transpose1, number=10000))\n",
    "print(timeit.timeit(int_transpose2, number=10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and back to pretty midi...\n",
    "def H2pm(H, O, V, tempo, sub_beat_times):\n",
    "    beat_length = 60 / tempo\n",
    "    sub_beat_length = beat_length / sub_beats\n",
    "    pm = pretty_midi.PrettyMIDI(resolution=960, tempo=tempo)\n",
    "    pm.instruments.append(pretty_midi.Instrument(0, name='piano'))\n",
    "    for timestep in range(len(H)):\n",
    "        for pitch in H(timestep):\n",
    "            noteM = pretty_midi.Note(64, pitch + 21, sub_beat_times[timestep], end)\n",
    "            pm.instruments[0].notes.append(noteM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16896.140625"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getsizeof(np.zeros((3,128,64,88), dtype=np.int64))/1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "<DirEntry 'aa_97_Cm.mid'>\n",
      "examples: 16\n",
      "sub beats per example: 64\n",
      "no. of sub beats: 1024\n",
      " \n",
      "<DirEntry 'ab_108_Eb.mid'>\n",
      "examples: 9\n",
      "sub beats per example: 64\n",
      "no. of sub beats: 576\n",
      " \n",
      "<DirEntry 'ac_82_Ebm.mid'>\n",
      "examples: 16\n",
      "sub beats per example: 64\n",
      "no. of sub beats: 1024\n",
      " \n",
      "<DirEntry 'ad_63_Am.mid'>\n",
      "examples: 14\n",
      "sub beats per example: 64\n",
      "no. of sub beats: 896\n",
      " \n",
      "<DirEntry 'ae_78_Am.mid'>\n",
      "examples: 35\n",
      "sub beats per example: 64\n",
      "no. of sub beats: 2240\n",
      " \n",
      "<DirEntry 'af_94_Bm.mid'>\n",
      "examples: 27\n",
      "sub beats per example: 64\n",
      "no. of sub beats: 1728\n",
      " \n",
      "<DirEntry 'ag_65_Gm.mid'>\n",
      "examples: 17\n",
      "sub beats per example: 64\n",
      "no. of sub beats: 1088\n",
      " \n",
      "<DirEntry 'ah_104_Bm.mid'>\n",
      "examples: 12\n",
      "sub beats per example: 64\n",
      "no. of sub beats: 768\n",
      " \n",
      "<DirEntry 'ai_79_D.mid'>\n",
      "examples: 14\n",
      "sub beats per example: 64\n",
      "no. of sub beats: 896\n",
      " \n",
      "<DirEntry 'aj_107_Em.mid'>\n",
      "examples: 6\n",
      "sub beats per example: 64\n",
      "no. of sub beats: 384\n",
      " \n",
      "<DirEntry 'ak_107_Ebm.mid'>\n",
      "examples: 77\n",
      "sub beats per example: 64\n",
      "no. of sub beats: 4928\n",
      " \n",
      "<DirEntry 'al_110_Ebm.mid'>\n",
      "examples: 40\n",
      "sub beats per example: 64\n",
      "no. of sub beats: 2560\n",
      " \n",
      "<DirEntry 'am_108_Em.mid'>\n",
      "examples: 18\n",
      "sub beats per example: 64\n",
      "no. of sub beats: 1152\n",
      "[array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.])]\n",
      "(64, 88)\n",
      "(64, 88)\n",
      "(64, 88)\n",
      "(12,)\n",
      "(1,)\n"
     ]
    }
   ],
   "source": [
    "model_datas = data.folder2examples('training_data\\midi_files', sparse=False)\n",
    "# with open('H2', 'wb') as f:\n",
    "#     pickle.dump(mode_datas, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input 0: H\n",
      "input 1: tempo\n",
      "input 2: key\n",
      "input 0: H\n",
      "input 1: V\n"
     ]
    }
   ],
   "source": [
    "n_notes=88\n",
    "model_input = namedtuple('input', 'name dim seq')\n",
    "model_output = namedtuple('output', 'name dim activation')\n",
    "\n",
    "# model inputs\n",
    "model_inputs = []\n",
    "model_inputs.append(model_input('H', n_notes, True))\n",
    "model_inputs.append(model_input('tempo', 1, False))\n",
    "model_inputs.append(model_input('key', 12, False))\n",
    "\n",
    "# model outputs\n",
    "model_outputs = []\n",
    "model_outputs.append(model_output('H', n_notes, 'sigmoid'))\n",
    "# model_outputs.append(model_output('O', n_notes, 'tanh'))\n",
    "model_outputs.append(model_output('V', n_notes, 'sigmoid'))\n",
    "\n",
    "# set up keras inputs\n",
    "seq_length = 64\n",
    "seq_inputs = [tf.keras.Input(shape=(seq_length,seq_in.dim), name=seq_in.name + '_in') for seq_in in model_inputs if seq_in.seq == True]\n",
    "aux_inputs = [tf.keras.Input(shape=(aux_in.dim,), name=aux_in.name + '_in') for aux_in in model_inputs if aux_in.seq == False]\n",
    "\n",
    "for i, model_input in enumerate(model_inputs):\n",
    "    print(f'input {i}: {model_input.name}')\n",
    "          \n",
    "for i, model_output in enumerate(model_outputs):\n",
    "    print(f'input {i}: {model_output.name}')\n",
    "    \n",
    "# # another possible way of doing this\n",
    "# model_inout = namedtuple('inout', 'name dim seq activation in out')\n",
    "# H_in = model_inout('H', n_notes, True, 'sigmoid', True, True)\n",
    "# tempo_in = model_inout('tempo', 1, False, None, True, False)\n",
    "# key_in = model_inout('key', 12, False, None, True, False)\n",
    "\n",
    "# O_out = model_inout('O', n_notes, True, 'tanh')\n",
    "# V_out = model_inout('V', n_notes, True, 'sigmoid', False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"autoencoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "tempo_in (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "key_in (InputLayer)             [(None, 12)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "H_in (InputLayer)               [(None, 64, 88)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "repeat64Times (RepeatVector)    multiple             0           tempo_in[0][0]                   \n",
      "                                                                 key_in[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "joinModelInput (Concatenate)    (None, 64, 101)      0           H_in[0][0]                       \n",
      "                                                                 repeat64Times[0][0]              \n",
      "                                                                 repeat64Times[1][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_6 (Bidirectional) (None, 64, 128)      84992       joinModelInput[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_7 (Bidirectional) (None, 128)          98816       bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 64)           8256        bidirectional_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "z (Dense)                       (None, 64)           4160        dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 64)           4160        z[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_1 (RepeatVector)  (None, 64, 64)       0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_8 (Bidirectional) (None, 64, 128)      66048       repeat_vector_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_9 (Bidirectional) (None, 64, 128)      98816       bidirectional_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_11 (LSTM)                  (None, 64, 64)       49408       bidirectional_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "H_out (TimeDistributed)         (None, 64, 88)       5720        lstm_11[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "V_out (TimeDistributed)         (None, 64, 88)       5720        lstm_11[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 426,096\n",
      "Trainable params: 426,096\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "z = models.create_LSTMencoder(seq_inputs, aux_inputs, seq_length=seq_length, lstm_layers = 2, dense_layers = 2, hidden_state_size = 64, latent_size = 64,\n",
    "                    dense_size = 64)\n",
    "outputs = models.create_LSTMdecoder(z, model_outputs, seq_length=seq_length, hidden_state_size = 64,\n",
    "                    dense_size = 64)\n",
    "model = tf.keras.Model(inputs=[seq_inputs + aux_inputs], outputs=outputs, name=f'autoencoder')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "10/10 [==============================] - 15s 1s/step - loss: 4.7004 - H_out_loss: 3.5235 - V_out_loss: 1.1769 - H_out_accuracy: 0.0088 - V_out_accuracy: 0.0074\n",
      "Epoch 2/3\n",
      "10/10 [==============================] - 15s 1s/step - loss: 4.6091 - H_out_loss: 3.4427 - V_out_loss: 1.1664 - H_out_accuracy: 0.0125 - V_out_accuracy: 0.0106\n",
      "Epoch 3/3\n",
      "10/10 [==============================] - 15s 2s/step - loss: 4.5881 - H_out_loss: 3.4325 - V_out_loss: 1.1555 - H_out_accuracy: 0.0080 - V_out_accuracy: 0.0106\n"
     ]
    }
   ],
   "source": [
    "# dg = ml_classes.ModelDataGenerator(model_datas, ['H', 'tempo', 'key'], ['H', 'V'], batch_size = 30, seq_length=seq_length)\n",
    "dg = ml_classes.ModelDataGenerator(model_datas, [model_in.name for model_in in model_inputs], [model_out.name for model_out in model_outputs], batch_size = 30, seq_length=seq_length)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# fit the model\n",
    "# key is not working.\n",
    "history = model.fit_generator(dg, epochs=3, verbose=1)\n",
    "# model.fit([model_datas2['H'], model_datas['tempo']],[model_datas['H'], model_datas['V']], epochs=3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.1 64-bit ('base': conda)",
   "language": "python",
   "name": "python37164bitbasecondae3e7ccf567c04673a097ad97a01807b4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
