{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-088f92c63dbd>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blah = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import numpy as np\n",
    "import os\n",
    "import copy\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import csc_matrix, csr_matrix\n",
    "import pickle\n",
    "import json\n",
    "import pretty_midi\n",
    "import sys\n",
    "from collections import namedtuple\n",
    "import timeit\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "# import my modules\n",
    "import src.midi_utils as midi_utils\n",
    "import src.data as data\n",
    "import src.models as models\n",
    "import src.ml_classes as ml_classes\n",
    "import src.exp_utils as exp_utils\n",
    "import src.losses as losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# seem to need this to use my custom loss function, see here: https://github.com/tensorflow/tensorflow/issues/34944\n",
    "# last answer might fix it: https://stackoverflow.com/questions/57704771/inputs-to-eager-execution-function-cannot-be-keras-symbolic-tensors\n",
    "# the trick is for the step that defines the loss fnc to return a symbolic tensor, rather than returning another function which uses a symbolic tensor\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "# alternatively, could do something like this?\n",
    "# https://github.com/Douboo/tf_env_debug/blob/master/custom_layers_and_model_subclassing_API.ipynb\n",
    "\n",
    "# data params\n",
    "model_inputs = ['H', 'V_mean']\n",
    "model_outputs = ['H', 'V']\n",
    "seq_length = 64\n",
    "sub_beats = 2\n",
    "use_base_key = True\n",
    "transpose = False\n",
    "st = 0\n",
    "nth_file = 10\n",
    "vel_cutoff = 4\n",
    "data_folder_prefix = '_8'\n",
    "\n",
    "##### Model Config ####\n",
    "### general network params\n",
    "hierarchical = False\n",
    "variational = True\n",
    "latent_size = 10\n",
    "hidden_state = 100\n",
    "dense_size = 100\n",
    "dense_layers = 2\n",
    "recurrent_dropout=0.0\n",
    "\n",
    "### encoder params\n",
    "encoder_lstms = 2\n",
    "z_activation = None\n",
    "conv = False\n",
    "# pitch_stride = 6\n",
    "# conv = {'F_n': [32, 32, 48, 48, 48, 24], # number of filters\n",
    "#         'F_s': [(8,12), (4,4), (4,4), (4,4), (4,4), (4,4)], # size of filters\n",
    "#         'strides': [(1, pitch_stride), (1, 1), (2, 1), (2,1), (2,1), (2,2)],  # strides\n",
    "#         'batch_norm': True # apply batch norm after each conv operation (after activation)\n",
    "#         }\n",
    "\n",
    "\n",
    "### sampling params... if applicable.\n",
    "epsilon_std=1\n",
    "\n",
    "### decoder params\n",
    "decoder_lstms=2\n",
    "# ar_inputs only works as parameter for non hierarchical graph, currently\n",
    "ar_inputs = None\n",
    "conductors=2\n",
    "conductor_steps= int(seq_length/16)\n",
    "conductor_state_size=None # none => same as decoder\n",
    "initial_state_from_dense=True\n",
    "initial_state_activation='tanh'\n",
    "\n",
    "##### Training Config ####\n",
    "batch_size = 64\n",
    "lr = 0.001\n",
    "lr_decay_rate = 0.2**(1/1500)\n",
    "min_lr = 0.00005\n",
    "epochs = 2\n",
    "monitor = 'loss'\n",
    "loss_weights = [1, 3]\n",
    "clipvalue = 1\n",
    "loss = losses.vae_custom_loss\n",
    "# loss = 'categorical_crossentropy'\n",
    "metrics = ['accuracy', 'categorical_crossentropy']\n",
    "\n",
    "# musicvae used 48 free bits for 2-bars, 256 for 16 bars (see https://arxiv.org/pdf/1803.05428.pdf)\n",
    "# Variational specific parameters\n",
    "max_beta = 0.05\n",
    "beta_rate = 0.2**(1/1000) # at 1000 epochs, we want (1 - something) * max_beta\n",
    "free_bits=0\n",
    "kl_weight = 1\n",
    "\n",
    "#other\n",
    "continue_run = None\n",
    "log_tensorboard = False\n",
    "ar_inc_batch_shape = False # sometimes needed to make training work...\n",
    "     \n",
    "\n",
    "blah = blah + 1\n",
    "no, path = exp_utils.set_up_path(blah)\n",
    "\n",
    "\n",
    "# get training data\n",
    "assert seq_length % 4 == 0, 'Sequence length must be divisible by 4'\n",
    "model_datas_train, seconds = data.folder2examples('training_data/midi_train' + data_folder_prefix, sparse=True, use_base_key=use_base_key, beats_per_ex=int(seq_length / sub_beats), nth_file=nth_file, vel_cutoff=vel_cutoff, sub_beats=sub_beats)\n",
    "model_datas_val, seconds = data.folder2examples('training_data/midi_val' + data_folder_prefix, sparse=True, use_base_key=use_base_key, beats_per_ex=int(seq_length / sub_beats), sub_beats=sub_beats)\n",
    "\n",
    "model_input_reqs, model_output_reqs = models.get_model_reqs(model_inputs, model_outputs)\n",
    "\n",
    "callbacks = []\n",
    "\n",
    "if log_tensorboard:\n",
    "    callbacks.append(tf.keras.callbacks.TensorBoard(log_dir='experiments/tb/', histogram_freq = 1))\n",
    "\n",
    "# model kwargs - for the encoder/decoder builder functions, make a dictionary to pass as kwargs\n",
    "model_kwargs = {# general model parameters\n",
    "                'recurrent_dropout':recurrent_dropout,\n",
    "                'hidden_state':hidden_state,\n",
    "                'dense_size':dense_size,\n",
    "                'seq_length':seq_length,\n",
    "\n",
    "                # encoder parameters\n",
    "                'latent_size':latent_size,\n",
    "                'z_activation':z_activation,\n",
    "                'variational':variational,\n",
    "                'conv':conv,\n",
    "\n",
    "                # decoder parameters\n",
    "                'ar_inputs':ar_inputs, \n",
    "                'decoder_lstms':decoder_lstms,\n",
    "                'batch_size':batch_size, # not used in encoder, currently...\n",
    "                'initial_state_from_dense':initial_state_from_dense,\n",
    "                'initial_state_activation':initial_state_activation,\n",
    "                'ar_inc_batch_shape':ar_inc_batch_shape,\n",
    "                'conv':conv,\n",
    "                # conductor configuration (only used if hierarchical)\n",
    "                'conductor_state_size':conductor_state_size, # none => same as decoder\n",
    "                'conductors':conductors,\n",
    "                'conductor_steps':conductor_steps,\n",
    "                }\n",
    "# if variational, z will be a list of [[means], [stds]]\n",
    "build_encoder_graph = models.create_LSTMencoder_graph\n",
    "z, model_inputs_tf = build_encoder_graph(model_input_reqs, **model_kwargs)\n",
    "\n",
    "if variational:\n",
    "    beta_fn = exp_utils.beta_fn2(beta_rate, max_beta)\n",
    "    loss_for_train, beta_cb = loss(z, beta_fn, free_bits=free_bits, kl_weight=kl_weight)\n",
    "    sampling_fn = models.sampling(batch_size, epsilon_std=epsilon_std)\n",
    "    # z_input is the tensor that will be passed into the decoder\n",
    "    z_input = layers.Lambda(sampling_fn)(z)\n",
    "    if not isinstance(beta_fn, (int, float)):\n",
    "        callbacks.append(beta_cb)\n",
    "else:\n",
    "    loss_for_train = loss\n",
    "    z_input = z\n",
    "\n",
    "if hierarchical:\n",
    "    build_decoder_graph = models.create_hierarchical_decoder_graph\n",
    "else:\n",
    "    build_decoder_graph =models.create_LSTMdecoder_graph_ar\n",
    "\n",
    "pred, ar_inputs_tf = build_decoder_graph(z_input, model_output_reqs, **model_kwargs)\n",
    "autoencoder = tf.keras.Model(inputs=model_inputs_tf + ar_inputs_tf, outputs=pred, name=f'autoencoder')\n",
    "autoencoder.summary()\n",
    "\n",
    "if continue_run != None:\n",
    "    autoencoder.load_weights(f'experiments/run_{continue_run}/{continue_run}_best_train_weights.hdf5')\n",
    "\n",
    "\n",
    "\n",
    "# save a plot of the model\n",
    "# tf.keras.utils.plot_model(seq_model, to_file=f'{path}model_plot.png')\n",
    "\n",
    "dg = ml_classes.ModelDataGenerator([md for md in model_datas_train.values()],\n",
    "                                    [model_in.name for model_in in model_input_reqs],\n",
    "                                    [model_out.name for model_out in model_output_reqs],\n",
    "                                    t_force=True, batch_size = batch_size, seq_length=seq_length)\n",
    "\n",
    "dg_val = ml_classes.ModelDataGenerator([md for md in model_datas_val.values()],\n",
    "                                    [model_in.name for model_in in model_input_reqs],\n",
    "                                    [model_out.name for model_out in model_output_reqs],\n",
    "                                    t_force=True, batch_size = batch_size, seq_length=seq_length)\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=lr, clipvalue=clipvalue)\n",
    "autoencoder.compile(optimizer=opt, loss=loss_for_train, metrics=metrics, loss_weights=loss_weights)\n",
    "# history = autoencoder.fit(dg, validation_data=dg_val, epochs=epochs, callbacks=callbacks, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules, including a reload statement so that they can be reimported after a change to the methods \n",
    "import src.midi_utils as midi_utils\n",
    "reload(midi_utils)\n",
    "\n",
    "import src.data as data\n",
    "reload(data)\n",
    "\n",
    "import src.models as models\n",
    "reload(models)\n",
    "\n",
    "import src.ml_classes as ml_classes\n",
    "reload(ml_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 1/12 [00:00<00:02,  5.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "velocity index: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:03<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00h 37m 53s of data\n",
      "created model data H :    (64, 88) data shape,     122 training examples\n",
      "created model data O :    (64, 88) data shape,     122 training examples\n",
      "created model data V :    (64, 88) data shape,     122 training examples\n",
      "created model data R :    (64, 88) data shape,     122 training examples\n",
      "created model data S :    (64, 2) data shape,     122 training examples\n",
      "created model data key :    (12,) data shape,     122 training examples\n",
      "created model data tempo :    (1,) data shape,     122 training examples\n",
      "created model data V_mean :    (1,) data shape,     122 training examples\n",
      "example 91 chosen\n",
      "example 91 chosen\n",
      "example 93 chosen\n",
      "simultaneous pedal events!\n",
      "example 93 chosen\n",
      "simultaneous pedal events!\n",
      "example 87 chosen\n",
      "example 87 chosen\n",
      "example 26 chosen\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "example 26 chosen\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "example 52 chosen\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "example 52 chosen\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "example 82 chosen\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "example 82 chosen\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "example 45 chosen\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "example 45 chosen\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "example 63 chosen\n",
      "simultaneous pedal events!\n",
      "example 63 chosen\n",
      "simultaneous pedal events!\n",
      "example 9 chosen\n",
      "example 9 chosen\n",
      "example 49 chosen\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "example 49 chosen\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "example 19 chosen\n",
      "example 19 chosen\n",
      "example 8 chosen\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "example 8 chosen\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "example 11 chosen\n",
      "simultaneous pedal events!\n",
      "example 11 chosen\n",
      "simultaneous pedal events!\n",
      "example 94 chosen\n",
      "simultaneous pedal events!\n",
      "example 94 chosen\n",
      "simultaneous pedal events!\n",
      "example 106 chosen\n",
      "example 106 chosen\n",
      "example 58 chosen\n",
      "example 58 chosen\n",
      "example 80 chosen\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "example 80 chosen\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "example 24 chosen\n",
      "example 24 chosen\n",
      "example 81 chosen\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "example 81 chosen\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "example 118 chosen\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "example 118 chosen\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "example 0 chosen\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "example 0 chosen\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "example 30 chosen\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "example 30 chosen\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "example 65 chosen\n",
      "simultaneous pedal events!\n",
      "example 65 chosen\n",
      "simultaneous pedal events!\n",
      "example 35 chosen\n",
      "example 35 chosen\n",
      "example 12 chosen\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "example 12 chosen\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "example 17 chosen\n",
      "example 17 chosen\n",
      "example 58 chosen\n",
      "example 58 chosen\n",
      "example 63 chosen\n",
      "simultaneous pedal events!\n",
      "example 63 chosen\n",
      "simultaneous pedal events!\n",
      "example 28 chosen\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "example 28 chosen\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "example 99 chosen\n",
      "example 99 chosen\n",
      "example 48 chosen\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "example 48 chosen\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "example 84 chosen\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "example 84 chosen\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "example 55 chosen\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "example 55 chosen\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "example 115 chosen\n",
      "simultaneous pedal events!\n",
      "example 115 chosen\n",
      "simultaneous pedal events!\n",
      "example 33 chosen\n",
      "example 33 chosen\n",
      "example 0 chosen\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "example 0 chosen\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "example 7 chosen\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "example 7 chosen\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "example 52 chosen\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "example 52 chosen\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "example 19 chosen\n",
      "example 19 chosen\n",
      "example 14 chosen\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "example 14 chosen\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "example 115 chosen\n",
      "simultaneous pedal events!\n",
      "example 115 chosen\n",
      "simultaneous pedal events!\n",
      "example 75 chosen\n",
      "simultaneous pedal events!\n",
      "example 75 chosen\n",
      "simultaneous pedal events!\n",
      "example 27 chosen\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "example 27 chosen\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "example 76 chosen\n",
      "example 76 chosen\n",
      "example 57 chosen\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "example 57 chosen\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "example 118 chosen\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "example 118 chosen\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "example 55 chosen\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "example 55 chosen\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "example 85 chosen\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "example 85 chosen\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "example 7 chosen\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "example 7 chosen\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "example 3 chosen\n",
      "simultaneous pedal events!\n",
      "example 3 chosen\n",
      "simultaneous pedal events!\n",
      "example 80 chosen\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "example 80 chosen\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "example 28 chosen\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "example 28 chosen\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "example 90 chosen\n",
      "example 90 chosen\n",
      "example 110 chosen\n",
      "example 110 chosen\n",
      "example 106 chosen\n",
      "example 106 chosen\n",
      "example 60 chosen\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "example 60 chosen\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "example 96 chosen\n",
      "example 96 chosen\n",
      "example 94 chosen\n",
      "simultaneous pedal events!\n",
      "example 94 chosen\n",
      "simultaneous pedal events!\n",
      "example 64 chosen\n",
      "example 64 chosen\n",
      "example 20 chosen\n",
      "example 20 chosen\n",
      "example 4 chosen\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "example 4 chosen\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "example 0 chosen\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "example 0 chosen\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "example 82 chosen\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "example 82 chosen\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "example 83 chosen\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "example 83 chosen\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n",
      "simultaneous pedal events!\n"
     ]
    }
   ],
   "source": [
    "### Make some predictions ###\n",
    "# load best weights\n",
    "# models.load_weights_safe(autoencoder, path + f'{no}_best_train_weights.hdf5', by_name=False)\n",
    "# get some random examples from the validation data\n",
    "random_examples, idx = data.n_rand_examples(model_datas_val, n=batch_size)\n",
    "\n",
    "# currently, prediction is broken for my variational models\n",
    "# if variational, then for now need to circumvent autoencoder.predict()\n",
    "if variational:\n",
    "    #grab encoder layers from above, make a model\n",
    "#     z, model_inputs_tf = build_encoder_graph(model_input_reqs, **model_kwargs)\n",
    "#     encoder = tf.keras.Model(inputs=model_inputs_tf, outputs=z, name=f'encoder')\n",
    "    \n",
    "    # create a new decoder\n",
    "    z_in = tf.keras.Input(shape=(latent_size,), name='z')\n",
    "    model_kwargs['ar_inc_batch_shape'] = False\n",
    "    pred, ar_inputs_tf = build_decoder_graph(z_in, model_output_reqs, **model_kwargs)\n",
    "    decoder = tf.keras.Model(inputs=[z_in] + ar_inputs_tf, outputs=pred, name=f'decoder')\n",
    "\n",
    "    # load weights for decoder\n",
    "    # models.load_weights_safe(decoder, path + f'{no}_best_train_weights.hdf5', by_name=True)\n",
    "\n",
    "    in_dict = dg_val.__getitem__(0)[0]\n",
    "\n",
    "    ### predict\n",
    "    # get paramerterization of latent space\n",
    "    zp_param = encoder.predict(in_dict)\n",
    "    # generate random values\n",
    "    zp_latent = sampling_fn(zp_param)\n",
    "    with tf.compat.v1.Session():\n",
    "        in_dict['z'] = zp_latent.eval()\n",
    "#         in_dict['z'] = np.zeros((64,10))\n",
    "    pred = decoder.predict(in_dict)\n",
    "\n",
    "else:\n",
    "    pred = autoencoder.predict(random_examples)\n",
    "\n",
    "# find axis that corresponds to velocity\n",
    "v_index = np.where(np.array(autoencoder.output_names) == 'V_out')[0][0]\n",
    "print('velocity index:', v_index)\n",
    "model_datas_pred, _ = data.folder2examples('training_data/midi_val' + data_folder_prefix, sparse=False, use_base_key=use_base_key, beats_per_ex=int(seq_length / sub_beats), sub_beats=sub_beats)\n",
    "model_datas = copy.deepcopy(model_datas_pred)\n",
    "model_datas_pred['V'].data[idx,...] = np.array(pred)[v_index,:,:,:]\n",
    "os.mkdir(path + 'midi/')\n",
    "for i in idx:\n",
    "    pm_original = data.examples2pm(model_datas, i, sub_beats=sub_beats)\n",
    "    pm_pred = data.examples2pm(model_datas_pred, i, sub_beats=sub_beats)\n",
    "    pm_original.write(path + 'midi/' + f'ex{i}original.mid')\n",
    "    pm_pred.write(path + 'midi/' + f'ex{i}prediction_teacher_forced.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 10)\n",
      "[<tf.Tensor 'z_4:0' shape=(None, 10) dtype=float32>, <tf.Tensor 'H_ar_5:0' shape=(64, 64, 88) dtype=float32>, <tf.Tensor 'V_ar_5:0' shape=(64, 64, 88) dtype=float32>]\n",
      "['H_in', 'V_mean_in', 'dummy', 'H_ar', 'V_ar', 'z']\n",
      "[(64, 64, 88), (64, 1), (64, 0), (64, 64, 88), (64, 64, 88), (64, 10)]\n",
      "Model: \"decoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "z (InputLayer)                  [(None, 10)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "initial_dense (Dense)           (None, 100)          1100        z[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_5 (RepeatVector)  (None, 64, 100)      0           initial_dense[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lstm_h0_0 (Dense)               (None, 100)          1100        z[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "lstm_c0_0 (Dense)               (None, 100)          1100        z[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "H_ar (InputLayer)               [(64, 64, 88)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "V_ar (InputLayer)               [(64, 64, 88)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_lstm_0 (LSTM)               (None, 64, 100)      80400       repeat_vector_5[0][0]            \n",
      "                                                                 lstm_h0_0[0][0]                  \n",
      "                                                                 lstm_c0_0[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (64, 64, 276)        0           H_ar[0][0]                       \n",
      "                                                                 V_ar[0][0]                       \n",
      "                                                                 dec_lstm_0[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lstm_h0_final (Dense)           (None, 100)          1100        z[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "lstm_c0_final (Dense)           (None, 100)          1100        z[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "dec_lstm_final (LSTM)           (64, 64, 100)        150800      concatenate_5[0][0]              \n",
      "                                                                 lstm_h0_final[0][0]              \n",
      "                                                                 lstm_c0_final[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "H_out (TimeDistributed)         (64, 64, 88)         8888        dec_lstm_final[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "V_out (TimeDistributed)         (64, 64, 88)         8888        dec_lstm_final[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 254,476\n",
      "Trainable params: 254,476\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(zp_latent.shape)\n",
    "\n",
    "print(decoder.inputs)\n",
    "print([a[0] for a in in_dict.items()])\n",
    "print([a[1].shape for a in in_dict.items()])\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 10)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zp_param[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {'z': np.zeros((64, 10)), 'H_ar': np.zeros((64, 64, 88)), 'V_ar': np.zeros((64, 64, 88))}\n",
    "with tf.compat.v1.Session():\n",
    "    decoder(a)[0].eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get training data\n",
    "assert seq_length % 4 == 0, 'Sequence length must be divisible by 4'\n",
    "model_datas_train, seconds = data.folder2examples('training_data/midi_train' + data_folder_prefix, sparse=True, use_base_key=use_base_key, beats_per_ex=int(seq_length / sub_beats), nth_file=nth_file, vel_cutoff=vel_cutoff, sub_beats=sub_beats)\n",
    "model_datas_val, seconds = data.folder2examples('training_data/midi_val' + data_folder_prefix, sparse=True, use_base_key=use_base_key, beats_per_ex=int(seq_length / sub_beats), sub_beats=sub_beats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_input_reqs, model_output_reqs = models.get_model_reqs(model_inputs, model_outputs)\n",
    "z_list, model_inputs_tf = models.create_LSTMencoder_graph(model_input_reqs,\n",
    "                                                hidden_state = hidden_state,\n",
    "                                                dense_size=dense_size,\n",
    "                                                latent_size=latent_size,\n",
    "                                                seq_length=seq_length,\n",
    "                                                recurrent_dropout=recurrent_dropout,\n",
    "                                                z_activation=z_activation,\n",
    "                                                variational=variational,\n",
    "                                                conv=conv)\n",
    "encoder = tf.keras.Model(inputs=model_inputs_tf, outputs=z_list, name=f'encoder')\n",
    "\n",
    "if variational:\n",
    "    beta_fn = exp_utils.beta_fn2(beta_rate, max_beta)\n",
    "    loss_for_train, beta_cb = loss(z_list, beta_fn, free_bits=free_bits, kl_weight=kl_weight)\n",
    "    sampling_fn = models.sampling(batch_size, epsilon_std=epsilon_std)\n",
    "    z_placeholder = layers.Lambda(sampling_fn)(z_list)\n",
    "else:\n",
    "    loss_for_train = loss\n",
    "\n",
    "z_param_tf = tf.keras.Input(shape=(2,latent_size), name='z')\n",
    "z_in_through_sfn = sampling_fn(z_param_tf)\n",
    "z_in = tf.keras.Input(shape=(latent_size,), name='z')\n",
    "pred, ar_inputs_tf = models.create_LSTMdecoder_graph_ar(z_in_through_sfn,\n",
    "                                                        model_output_reqs,\n",
    "                                                        seq_length=seq_length,\n",
    "                                                        hidden_state=hidden_state,\n",
    "                                                        dense_size=dense_size,\n",
    "                                                        ar_inputs=ar_inputs,\n",
    "                                                        recurrent_dropout=recurrent_dropout,\n",
    "                                                        initial_state_from_dense=initial_state_from_dense,\n",
    "                                                        initial_state_activation=initial_state_activation,\n",
    "                                                        batch_size=batch_size,\n",
    "                                                        ar_inc_batch_shape=ar_inc_batch_shape)\n",
    "decoder = tf.keras.Model(inputs=[z_in] + ar_inputs_tf, outputs=pred, name=f'decoder')\n",
    "\n",
    "pred2 = decoder(z_placeholder)\n",
    "autoencoder = tf.keras.Model(inputs=model_inputs_tf + ar_inputs_tf, outputs=pred2, name=f'autoencoder')\n",
    "autoencoder.summary()\n",
    "\n",
    "# if continue_run != None:\n",
    "#     autoencoder.load_weights(f'experiments/run_{continue_run}/{continue_run}_best_train_weights.hdf5')\n",
    "\n",
    "\n",
    "\n",
    "# save a plot of the model\n",
    "# tf.keras.utils.plot_model(seq_model, to_file=f'{path}model_plot.png')\n",
    "\n",
    "dg = ml_classes.ModelDataGenerator([md for md in model_datas_train.values()],\n",
    "                                    [model_in.name for model_in in model_input_reqs],\n",
    "                                    [model_out.name for model_out in model_output_reqs],\n",
    "                                    t_force=True, batch_size = batch_size, seq_length=seq_length)\n",
    "\n",
    "dg_val = ml_classes.ModelDataGenerator([md for md in model_datas_val.values()],\n",
    "                                    [model_in.name for model_in in model_input_reqs],\n",
    "                                    [model_out.name for model_out in model_output_reqs],\n",
    "                                    t_force=True, batch_size = batch_size, seq_length=seq_length)\n",
    "\n",
    "# opt = tf.keras.optimizers.Adam(learning_rate=lr, clipvalue=clipvalue)\n",
    "# autoencoder.compile(optimizer=opt, loss=loss_for_train, metrics=metrics, loss_weights=loss_weights)\n",
    "# history = autoencoder.fit(dg, validation_data=dg_val, epochs=epochs, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = tf.keras.Model(inputs=model_inputs_tf, outputs=z_list, name=f'encoder')\n",
    "decoder = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del encoder\n",
    "# del decoder\n",
    "# del pred\n",
    "# del ar_inputs\n",
    "# tf.keras.backend.clear_session()\n",
    "# z_list, model_inputs_tf = models.create_LSTMencoder_graph(model_input_reqs,\n",
    "#                                                 hidden_state = hidden_state,\n",
    "#                                                 dense_size=dense_size,\n",
    "#                                                 latent_size=latent_size,\n",
    "#                                                 seq_length=seq_length,\n",
    "#                                                 recurrent_dropout=recurrent_dropout,\n",
    "#                                                 z_activation=z_activation,\n",
    "#                                                 variational=variational,\n",
    "#                                                 conv=conv)\n",
    "encoder = tf.keras.Model(inputs=model_inputs_tf, outputs=z_list, name=f'encoder')\n",
    "z_in = tf.keras.Input(shape=(latent_size,), name='z')\n",
    "pred, ar_inputs_tf = models.create_LSTMdecoder_graph_ar(z_in,\n",
    "                                                    model_output_reqs,\n",
    "                                                    seq_length=seq_length,\n",
    "                                                    hidden_state=hidden_state,\n",
    "                                                    dense_size=dense_size,\n",
    "                                                    ar_inputs=ar_inputs,\n",
    "                                                    recurrent_dropout=recurrent_dropout,\n",
    "                                                    initial_state_from_dense=initial_state_from_dense,\n",
    "                                                    initial_state_activation=initial_state_activation,\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    ar_inc_batch_shape=ar_inc_batch_shape)\n",
    "decoder = tf.keras.Model(inputs=[z_in] + ar_inputs_tf, outputs=pred, name=f'decoder')\n",
    "autoencoder.save_weights(f'experiments/run_{no}/{no}_best_train_weights.hdf5')\n",
    "models.load_weights_safe(decoder, path + f'{no}_best_train_weights.hdf5', by_name=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abb(b,a,c=3, d=4, **kwargs):\n",
    "    print(a)\n",
    "    print(b)\n",
    "    print(c)\n",
    "    print(d)\n",
    "\n",
    "kw={'b':1, 'a':2, 'c':3, 'd':4}\n",
    "abb(**kw)\n",
    "print(kw)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zp_param = encoder.predict(dg.__getitem__(0)[0])\n",
    "np.array(zp_param).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zp_latent = sampling_fn(zp_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zp_latent.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = autoencoder(dg.__getitem__(0)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[1].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sess = tf.Session()\n",
    "in_dict = dg.__getitem__(0)[0]\n",
    "\n",
    "with tf.compat.v1.Session():\n",
    "    in_dict['z'] = zp_latent.eval()\n",
    "pred = decoder.predict(in_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Make some predictions ###\n",
    "# load best weights\n",
    "# models.load_weights_safe(autoencoder, path + f'{no}_best_train_weights.hdf5', by_name=False)\n",
    "# get some random examples from the validation data\n",
    "random_examples, idx = data.n_rand_examples(model_datas_val, n=batch_size)\n",
    "pred = autoencoder.predict(random_examples)\n",
    "# find axis that corresponds to velocity\n",
    "v_index = np.where(np.array(autoencoder.output_names) == 'V_out')[0][0]\n",
    "print('velocity index:', v_index)\n",
    "model_datas_pred, _ = data.folder2examples('training_data/midi_val' + data_folder_prefix, sparse=False, use_base_key=use_base_key, beats_per_ex=int(seq_length / sub_beats), sub_beats=sub_beats)\n",
    "model_datas = copy.deepcopy(model_datas_pred)\n",
    "model_datas_pred['V'].data[idx,...] = np.array(pred)[v_index,:,:,:]\n",
    "os.mkdir(path + 'midi/')\n",
    "for i in idx:\n",
    "    pm_original = data.examples2pm(model_datas, i, sub_beats=sub_beats)\n",
    "    pm_pred = data.examples2pm(model_datas_pred, i, sub_beats=sub_beats)\n",
    "    pm_original.write(path + 'midi/' + f'ex{i}original.mid')\n",
    "    pm_pred.write(path + 'midi/' + f'ex{i}prediction_teacher_forced.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.n_rand_examples(model_datas_val, n=batch_size)\n",
    "\n",
    "# pred = autoencoder.predict(dg.__getitem__(0)[0])\n",
    "[len(a) for a in dg.__getitem__(0)[0].values()]\n",
    "[a for a in dg.__getitem__(0)[0].keys()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
