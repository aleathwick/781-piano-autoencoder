{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-088f92c63dbd>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blah = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import numpy as np\n",
    "import os\n",
    "import copy\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import csc_matrix, csr_matrix\n",
    "import pickle\n",
    "import json\n",
    "import pretty_midi\n",
    "import sys\n",
    "from collections import namedtuple\n",
    "import timeit\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "# import my modules\n",
    "import src.midi_utils as midi_utils\n",
    "import src.data as data\n",
    "import src.models as models\n",
    "import src.ml_classes as ml_classes\n",
    "import src.exp_utils as exp_utils\n",
    "import src.losses as losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data params\n",
    "model_inputs = ['Pn', 'TBn', 'TSBn']\n",
    "model_outputs = ['Vn']\n",
    "seq_length = 50\n",
    "sub_beats = 2\n",
    "example_bars_skip = 4\n",
    "use_base_key = False\n",
    "transpose = False\n",
    "st = 0\n",
    "nth_file = 15\n",
    "vel_cutoff = 6\n",
    "data_folder_prefix = '_8'\n",
    "\n",
    "##### Model Config ####\n",
    "### general network params\n",
    "hidden_state = 200\n",
    "recurrent_dropout=0.0\n",
    "\n",
    "### encoder params\n",
    "bi_encoder_lstms = 2\n",
    "uni_encoder_lstms = 1\n",
    "conv = False\n",
    "ar_inputs = None\n",
    "# pitch_stride = 6\n",
    "# conv = {'F_n': [32, 32, 48, 48, 48, 24], # number of filters\n",
    "#         'F_s': [(8,12), (4,4), (4,4), (4,4), (4,4), (4,4)], # size of filters\n",
    "#         'strides': [(1, pitch_stride), (1, 1), (2, 1), (2,1), (2,1), (2,2)],  # strides\n",
    "#         'batch_norm': True # apply batch norm after each conv operation (after activation)\n",
    "#         }\n",
    "\n",
    "##### Training Config ####\n",
    "batch_size = 64\n",
    "lr = 0.001\n",
    "lr_decay_rate = 0.3**(1/1500)\n",
    "min_lr = 0.00005\n",
    "epochs = 2\n",
    "monitor = 'loss'\n",
    "loss_weights = None\n",
    "clipvalue = 1\n",
    "loss = 'mse'\n",
    "metrics = ['accuracy', 'mse']\n",
    "\n",
    "# musicvae used 48 free bits for 2-bars, 256 for 16 bars (see https://arxiv.org/pdf/1803.05428.pdf)\n",
    "# Variational specific parameters\n",
    "max_beta = 3\n",
    "beta_rate = 0.2**(1/1000) # at 1000 epochs, we want (1 - something) * max_beta\n",
    "free_bits=0\n",
    "kl_weight = 1\n",
    "\n",
    "#other\n",
    "continue_run = None\n",
    "log_tensorboard = False\n",
    "ar_inc_batch_shape = False # sometimes needed to make training work..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'src.ml_classes' from '/storage/781-piano-autoencoder/src/ml_classes.py'>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import modules, including a reload statement so that they can be reimported after a change to the methods \n",
    "import src.midi_utils as midi_utils\n",
    "reload(midi_utils)\n",
    "\n",
    "import src.data as data\n",
    "reload(data)\n",
    "\n",
    "import src.models as models\n",
    "reload(models)\n",
    "\n",
    "import src.ml_classes as ml_classes\n",
    "reload(ml_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:05<00:00,  2.88it/s]\n",
      "  8%|▊         | 1/12 [00:00<00:01,  7.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00h 43m 51s of data\n",
      "created model data TSn :    (50,) data shape,     278 training examples\n",
      "created model data TEn :    (50,) data shape,     278 training examples\n",
      "created model data TBn :    (50, 4) data shape,     278 training examples\n",
      "created model data TMn :    (50, 16) data shape,     278 training examples\n",
      "created model data TSBn :    (50, 2) data shape,     278 training examples\n",
      "created model data Pn :    (50, 88) data shape,     278 training examples\n",
      "created model data PSn :    (50, 1) data shape,     278 training examples\n",
      "created model data PCn :    (50, 12) data shape,     278 training examples\n",
      "created model data Vn :    (50, 1) data shape,     278 training examples\n",
      "created model data tempo :    (1,) data shape,     278 training examples\n",
      "created model data key :    (12,) data shape,     278 training examples\n",
      "created model data V_mean :    (1,) data shape,     278 training examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:03<00:00,  3.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00h 38m 47s of data\n",
      "created model data TSn :    (50,) data shape,     250 training examples\n",
      "created model data TEn :    (50,) data shape,     250 training examples\n",
      "created model data TBn :    (50, 4) data shape,     250 training examples\n",
      "created model data TMn :    (50, 16) data shape,     250 training examples\n",
      "created model data TSBn :    (50, 2) data shape,     250 training examples\n",
      "created model data Pn :    (50, 88) data shape,     250 training examples\n",
      "created model data PSn :    (50, 1) data shape,     250 training examples\n",
      "created model data PCn :    (50, 12) data shape,     250 training examples\n",
      "created model data Vn :    (50, 1) data shape,     250 training examples\n",
      "created model data tempo :    (1,) data shape,     250 training examples\n",
      "created model data key :    (12,) data shape,     250 training examples\n",
      "created model data V_mean :    (1,) data shape,     250 training examples\n",
      "Model: \"bi_uni_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "TBn_in (InputLayer)             [(None, 50, 4)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "TSBn_in (InputLayer)            [(None, 50, 2)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Pn_in (InputLayer)              [(None, 50, 88)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "joinModelInput (Concatenate)    (None, 50, 94)       0           TBn_in[0][0]                     \n",
      "                                                                 TSBn_in[0][0]                    \n",
      "                                                                 Pn_in[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bi_enc_lstm_0 (Bidirectional)   (None, 50, 400)      472000      joinModelInput[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bi_enc_lstm_1 (Bidirectional)   (None, 50, 400)      961600      bi_enc_lstm_0[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Vn_ar (InputLayer)              [(None, 50, 1)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bi_enc_lstm_2 (Bidirectional)   (None, 50, 400)      961600      bi_enc_lstm_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 50, 401)      0           Vn_ar[0][0]                      \n",
      "                                                                 bi_enc_lstm_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "uni_lstm_0 (LSTM)               (None, 50, 200)      481600      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "uni_lstm_1 (LSTM)               (None, 50, 200)      320800      uni_lstm_0[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Vn_out (Dense)                  (None, 50, 1)        201         uni_lstm_1[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 3,197,801\n",
      "Trainable params: 3,197,801\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/2\n",
      "\n",
      "Epoch 00001: loss improved from inf to 0.02697, saving model to test/0_best_train_weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02379, saving model to test/0_best_val_weights.hdf5\n",
      "4/4 - 5s - loss: 0.0270 - accuracy: 0.0000e+00 - mse: 0.0270 - val_loss: 0.0238 - val_accuracy: 0.0000e+00 - val_mse: 0.0238 - lr: 9.9920e-04\n",
      "Epoch 2/2\n",
      "\n",
      "Epoch 00002: loss improved from 0.02697 to 0.02093, saving model to test/0_best_train_weights.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.02379 to 0.02083, saving model to test/0_best_val_weights.hdf5\n",
      "4/4 - 2s - loss: 0.0209 - accuracy: 0.0000e+00 - mse: 0.0209 - val_loss: 0.0208 - val_accuracy: 0.0000e+00 - val_mse: 0.0208 - lr: 9.9840e-04\n"
     ]
    }
   ],
   "source": [
    "path = 'test/'\n",
    "no = 0\n",
    "model_datas_train, seconds = data.folder2nbq('training_data/midi_train' + data_folder_prefix, \n",
    "                                            return_ModelData_object=True,\n",
    "                                            seq_length=seq_length, \n",
    "                                            sub_beats=sub_beats, \n",
    "                                            example_bars_skip=example_bars_skip, \n",
    "                                            use_base_key=use_base_key, \n",
    "                                            nth_file=nth_file, \n",
    "                                            vel_cutoff=vel_cutoff)\n",
    "\n",
    "model_datas_val, seconds = data.folder2nbq('training_data/midi_val' + data_folder_prefix, \n",
    "                                        return_ModelData_object=True,\n",
    "                                        seq_length=seq_length, \n",
    "                                        sub_beats=sub_beats, \n",
    "                                        example_bars_skip=example_bars_skip, \n",
    "                                        use_base_key=use_base_key, \n",
    "                                        vel_cutoff=vel_cutoff)\n",
    "\n",
    "\n",
    "model_input_reqs, model_output_reqs = models.get_model_reqs(model_inputs, model_outputs, sub_beats=sub_beats)\n",
    "\n",
    "callbacks = []\n",
    "# train loss model checkpoint\n",
    "callbacks.append(tf.keras.callbacks.ModelCheckpoint(path + f'{no}_best_train_weights.hdf5',\n",
    "                            monitor='loss', verbose=1, save_best_only=True, save_weights_only=True))\n",
    "# val loss model checkpoint\n",
    "callbacks.append(tf.keras.callbacks.ModelCheckpoint(path + f'{no}_best_val_weights.hdf5',\n",
    "                            monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=True))\n",
    "# early stopping, if needed\n",
    "callbacks.append(tf.keras.callbacks.EarlyStopping(monitor=monitor, min_delta=0, patience=15))\n",
    "# learning rate scheduler\n",
    "callbacks.append(LearningRateScheduler(exp_utils.decay_lr(min_lr, lr_decay_rate)))\n",
    "# log to tensorboard\n",
    "if log_tensorboard:\n",
    "    callbacks.append(tf.keras.callbacks.TensorBoard(log_dir='experiments/tb/', histogram_freq = 1))\n",
    "\n",
    "# model kwargs - for the encoder/decoder builder functions, make a dictionary to pass as kwargs\n",
    "model_kwargs = {# general model parameters\n",
    "                'recurrent_dropout':recurrent_dropout,\n",
    "                'hidden_state':hidden_state,\n",
    "                'seq_length':seq_length,\n",
    "                'uni_encoder_lstms':uni_encoder_lstms,\n",
    "                'bi_encoder_lstms':bi_encoder_lstms,\n",
    "                'conv':conv,\n",
    "\n",
    "                # decoder parameters\n",
    "                'ar_inputs':ar_inputs,\n",
    "                'batch_size':batch_size, # not used in encoder, currently...\n",
    "                'ar_inc_batch_shape':ar_inc_batch_shape,\n",
    "                'conv':conv,\n",
    "                }\n",
    "\n",
    "inputs_tf, pred = models.create_nbq_bi_graph(model_input_reqs, model_output_reqs, **model_kwargs)\n",
    "\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs_tf, outputs=pred, name=f'bi_uni_model')\n",
    "model.summary()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# save a plot of the model\n",
    "# tf.keras.utils.plot_model(seq_model, to_file=f'{path}model_plot.png')\n",
    "\n",
    "dg = ml_classes.ModelDataGenerator([md for md in model_datas_train.values()],\n",
    "                                    [model_in.name for model_in in model_input_reqs if model_in.md],\n",
    "                                    [model_out.name for model_out in model_output_reqs if model_out.md],\n",
    "                                    t_force=True, batch_size = batch_size, seq_length=seq_length,\n",
    "                                    sub_beats=sub_beats, V_no_zeros=False)\n",
    "\n",
    "dg_val = ml_classes.ModelDataGenerator([md for md in model_datas_val.values()],\n",
    "                                    [model_in.name for model_in in model_input_reqs if model_in.md],\n",
    "                                    [model_out.name for model_out in model_output_reqs if model_out.md],\n",
    "                                    t_force=True, batch_size = batch_size, seq_length=seq_length,\n",
    "                                    sub_beats=sub_beats, V_no_zeros=False)\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=lr, clipvalue=clipvalue)\n",
    "\n",
    "\n",
    "\n",
    "model.compile(optimizer=opt, loss=loss, metrics=metrics, loss_weights=loss_weights)\n",
    "\n",
    "\n",
    "if continue_run != None:\n",
    "    model.load_weights(f'experiments/run_{continue_run}/{continue_run}_best_train_weights.hdf5')\n",
    "\n",
    "history = model.fit(dg, validation_data=dg_val, epochs=epochs, callbacks=callbacks, verbose=2)\n",
    "\n",
    "\n",
    "# save the model history\n",
    "with open(f'{path}history-{epochs}epochs.json', 'w') as f:\n",
    "    json.dump(str(history.history), f)\n",
    "\n",
    "# add weights to sacred... Or not, they can exceed max size! \n",
    "# exp_utils.capture_weights(_run)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "velocity index: 0\n"
     ]
    }
   ],
   "source": [
    "pred_tf = model.predict(random_examples)\n",
    "# find axis that corresponds to velocity\n",
    "v_index = np.where(np.array(model.output_names) == 'Vn_out')[0][0]\n",
    "print('velocity index:', v_index)\n",
    "model_datas_pred_tf = copy.deepcopy(model_datas_val)\n",
    "model_datas_pred_tf['Vn'].data[idx,...] = np.array(pred_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 1)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(pred_tf)[v_index,...].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights loaded successfully\n",
      "weights loaded successfully\n"
     ]
    }
   ],
   "source": [
    "model_kwargs.update({'stateful': True})\n",
    "reqs_tf = models.create_nbq_bi_graph(model_input_reqs, model_output_reqs, **model_kwargs)\n",
    "\n",
    "encoder = tf.keras.Model(inputs=reqs_tf['encoder_input'], outputs=reqs_tf['encoder_output'], name=f'encoder')\n",
    "decoder = tf.keras.Model(inputs=reqs_tf['decoder_input'], outputs=reqs_tf['decoder_output'], name=f'decoder')\n",
    "\n",
    "models.load_weights_safe(encoder, path + f'{no}_best_val_weights.hdf5', by_name=True)\n",
    "models.load_weights_safe(decoder, path + f'{no}_best_val_weights.hdf5', by_name=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "velocity index: 0\n"
     ]
    }
   ],
   "source": [
    "random_examples, idx = data.n_rand_examples(model_datas_val, n=batch_size)\n",
    "v_index = np.where(np.array(model.output_names) == 'Vn_out')[0][0]\n",
    "print('velocity index:', v_index)\n",
    "random_examples['encoded'] = encoder.predict(random_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[Errno 17] File exists: 'test/midi/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-105-5c1b26b05e04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mmodel_datas_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_datas_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mmodel_datas_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Vn'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'midi/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mmds_orig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mmd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_datas_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: 'test/midi/'"
     ]
    }
   ],
   "source": [
    "pred = np.zeros((batch_size, seq_length))\n",
    "\n",
    "Vn_out = np.zeros((batch_size,1,1))\n",
    "for i in range(seq_length):\n",
    "    step_input = {'encoded': random_examples['encoded'][:,i,:][:,None,:], 'Vn_ar': Vn_out}\n",
    "#     step_input = {'encoded': np.zeros((64,1,400)), 'Vn_ar': Vn_out}\n",
    "    Vn_out = decoder.predict(step_input, batch_size=batch_size)\n",
    "    pred[:,i] = Vn_out.flatten()\n",
    "\n",
    "model_datas_pred = copy.deepcopy(model_datas_val)\n",
    "model_datas_pred['Vn'].data[idx,...] = pred[...,None]\n",
    "os.mkdir(path + 'midi/')\n",
    "for i in idx:\n",
    "    mds_orig = {md.name: md.data[i] for _, md in model_datas_val.items()}\n",
    "    mds_pred = {md.name: md.data[i] for _, md in model_datas_pred.items()}\n",
    "    pm_original = data.nbq2pm(mds_orig)\n",
    "    pm_pred = data.nbq2pm(mds_pred)\n",
    "    pm_original.write(path + 'midi/' + f'ex{i}original.mid')\n",
    "    pm_pred.write(path + 'midi/' + f'ex{i}prediction_teacher_forced.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 1, 1)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(pred).shape\n",
    "Vn_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.35264522, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.35529041, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.35734826, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.35198653, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.35377997, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.35339791, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = np.zeros((batch_size, seq_length))\n",
    "pred[:,0] = Vn_out.flatten()\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 1, 400])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.keras.Input(shape=(1,hidden_state * 2), name=f'encoded')\n",
    "[64] + x.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'src.ml_classes' from '/storage/781-piano-autoencoder/src/ml_classes.py'>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import modules, including a reload statement so that they can be reimported after a change to the methods \n",
    "import src.midi_utils as midi_utils\n",
    "reload(midi_utils)\n",
    "\n",
    "import src.data as data\n",
    "reload(data)\n",
    "\n",
    "import src.models as models\n",
    "reload(models)\n",
    "\n",
    "import src.ml_classes as ml_classes\n",
    "reload(ml_classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
