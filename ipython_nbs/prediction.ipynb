{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import pymongo\n",
    "import gridfs\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "from scipy.sparse import csc_matrix, csr_matrix\n",
    "import pickle\n",
    "import pretty_midi\n",
    "import sys\n",
    "import copy\n",
    "from collections import namedtuple\n",
    "import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules, including a reload statement so that they can be reimported after a change to the methods \n",
    "import src.midi_utils as midi_utils\n",
    "reload(midi_utils)\n",
    "\n",
    "import src.data as data\n",
    "reload(data)\n",
    "\n",
    "import src.models as models\n",
    "reload(models)\n",
    "\n",
    "import src.ml_classes as ml_classes\n",
    "reload(ml_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting Velocities\n",
    "Getting predictions out of a few models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in os.scandir('training_data/mtt'):\n",
    "    print(i.is_dir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_datas, seconds = data.folder2examples('training_data/midi_val_8', sparse=False, use_base_key=True, beats_per_ex=16, sub_beats=2)\n",
    "model_datas_pred = copy.deepcopy(model_datas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rands, idx = data.n_rand_examples(model_datas)\n",
    "rands, idx = data.n_rand_examples(model_datas_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Bi LSTM Model: Zero vs Non-Zero Entries\n",
    "Here was the first time I realised the MSE_zero + MSE_note issue might pose a problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_input_reqs, model_output_reqs = models.get_model_reqs(['H', 'V_mean'], ['V'])\n",
    "\n",
    "hidden_state = 256\n",
    "lstm_layers = 2\n",
    "dense_layers = 1\n",
    "dense_size = 128\n",
    "seq_model = models.create_simple_LSTM_RNN(model_input_reqs, model_output_reqs, seq_length=seq_length, dense_layers=dense_layers, dense_size=dense_size)\n",
    "seq_model.summary()\n",
    "tf.keras.utils.plot_model(seq_model)\n",
    "\n",
    "# load some weights\n",
    "seq_model.load_weights('89-0.31.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V_pred = seq_model.predict({md.name + '_in': md.data for md in model_datas.values()})\n",
    "\n",
    "# get predictions for indices where a note exists, or doesn't exist\n",
    "V_pred_ones = V_pred[np.where(model_datas['H'].data == 1)]\n",
    "V_pred_zeros = V_pred[np.where(model_datas['H'].data != 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some plotting of note velocity predictions: mostly zeros or ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot frequencies of different velocities - we see that the model is biased towards predicting values close to 0 or 1\n",
    "plt.figure(figsize=(9,6))\n",
    "plt.yscale('log')\n",
    "plt.hist(V_pred.flatten(), bins=40)\n",
    "plt.title('Model 004 Velocities')\n",
    "plt.xlabel('Velocity')\n",
    "plt.ylabel('Frequency')\n",
    "# plt.savefig('004-velocities')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how about plotting velocities for the positions where there are notes?\n",
    "# all the zero velocity predictions are gone. I.e. this model is just learning to reproduce input.\n",
    "plt.figure(figsize=(9,6))\n",
    "# plt.yscale('log')\n",
    "plt.hist(V_pred_ones, bins=40)\n",
    "plt.title('Model 004 Velocities')\n",
    "plt.xlabel('Velocity')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# velocities for positions where there are no notes\n",
    "plt.figure(figsize=(9,6))\n",
    "plt.yscale('log')\n",
    "plt.hist(V_pred_zeros, bins=40)\n",
    "plt.title('Model 004 Velocities')\n",
    "plt.xlabel('Velocity')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### look at correlation between real and predicted velocities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(V_pred_ones, model_datas['V'].data[np.where(model_datas['H'].data == 1)])\n",
    "# V_pred_ones.shape\n",
    "# model_datas['V'].data[np.where(model_datas['H'].data == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(V_pred_ones, model_datas['V'].data[np.where(model_datas['H'].data == 1)], alpha=0.03)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### write predictions to midi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Autoencoder Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.models as models\n",
    "reload(models)\n",
    "\n",
    "# data params\n",
    "model_inputs = ['H', 'V_mean']\n",
    "model_outputs = ['H', 'V']\n",
    "seq_length = 64\n",
    "use_base_key = True\n",
    "transpose = False\n",
    "st = 0\n",
    "nth_file = None\n",
    "\n",
    "# network params\n",
    "hierarchical = False\n",
    "initial_state_from_dense = False\n",
    "hidden_state = 512\n",
    "lstm_layers = 2\n",
    "dense_layers = 1\n",
    "dense_size = 512\n",
    "latent_size = 256\n",
    "batch_size = 64\n",
    "# ar_inputs only works as parameter for non hierarchical graph, currently\n",
    "ar_inputs = None\n",
    "\n",
    "\n",
    "model_input_reqs, model_output_reqs = models.get_model_reqs(model_inputs, model_outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z, model_inputs = models.create_LSTMencoder_graph(model_input_reqs, hidden_state_size=hidden_state, dense_size=dense_size, latent_size=latent_size, seq_length=seq_length)\n",
    "encoder = tf.keras.Model(inputs=model_inputs, outputs=z, name=f'encoder')\n",
    "\n",
    "z_input = tf.keras.Input(batch_shape=(1,)+z.shape[1:], name='z_in')\n",
    "\n",
    "# must be stateful! With sequence length of 1.\n",
    "pred, ar_inputs = models.create_LSTMdecoder_graph_ar(z_input, model_output_reqs, seq_length=1, hidden_state_size = hidden_state, dense_size=dense_size, stateful=True)\n",
    "\n",
    "decoder = tf.keras.Model(inputs=[z_input] + ar_inputs, outputs=pred, name=f'decoder')\n",
    "\n",
    "encoder.summary()\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = 59\n",
    "encoder.load_weights(f'experiments/run_{run}/{run}_best_train_weights.hdf5', by_name=True)\n",
    "decoder.load_weights(f'experiments/run_{run}/{run}_best_train_weights.hdf5', by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab some examples, and predict z\n",
    "idx = [0,45,70,100,125,150]\n",
    "random_examples = {}\n",
    "\n",
    "for md in model_datas.values():\n",
    "    random_examples[md.name + '_in'] = md.data[idx,...]\n",
    "    random_examples[md.name + '_in'] = random_examples[md.name + '_in']\n",
    "    if md.seq:\n",
    "        random_examples[md.name + '_ar'] = np.concatenate([np.zeros((len(idx),1, md.dim)), md.data[idx,...][:,:-1]], axis=-2)\n",
    "z_pred = encoder.predict(random_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on z\n",
    "pred = []\n",
    "inputs = {}\n",
    "# get required ar inputs from model datas - these are just zeros\n",
    "for out in model_output_reqs:\n",
    "    if out.seq:\n",
    "        inputs[out.name + '_ar'] = np.zeros((1,1,out.dim))\n",
    "print([f'{name}: {md_in.shape}' for name, md_in in inputs.items()])\n",
    "\n",
    "# What will unavailable for prediction?\n",
    "non_accessible = ['V']\n",
    "\n",
    "filter_ar_pos = True # whether to set all ar inputs to zero for positions with no notes \n",
    "for j, z in enumerate(z_pred):\n",
    "    decoder.reset_states()\n",
    "    # get latent vector\n",
    "    inputs['z_in'] = np.expand_dims(z, 0)\n",
    "    outputs_pred = []\n",
    "    # iterate over timesteps\n",
    "    for i in range(seq_length):\n",
    "        # get the ar inputs\n",
    "        for out in model_output_reqs:\n",
    "            # will only be ar inputs if seq is true\n",
    "            # in practice, not all seq inputs might be required by the model - but the model will select these by name if they are all passed\n",
    "            if out.seq and out.name not in non_accessible:\n",
    "                # need to expand dims - it is still seq data, just with time step of one\n",
    "                inputs[out.name + '_ar'] = np.expand_dims(np.expand_dims(random_examples[out.name + '_ar'][j,i], 0), 0)\n",
    "        decoded = decoder.predict(inputs)\n",
    "        # iterate over outputs - feed put them into inputs\n",
    "        # ignores whether the model actually needs them all autoregressively!\n",
    "        for output_name, output in zip(decoder.output_names, decoded):\n",
    "            input_name = output_name.split('_')[0] + '_ar'\n",
    "            if filter_ar_pos:\n",
    "                # set positions where there are no notes to zero\n",
    "                # this assumes that all outputs have same dimensions as H! i.e., 88\n",
    "                # this might error out, because of extra dimension on output\n",
    "                output[:,:,np.where(random_examples['H_in'][j,i] != 1)[0]] = 0\n",
    "                inputs[input_name] = np.expand_dims(np.expand_dims(output, 0), 0)\n",
    "            # give outputs back autoregressively\n",
    "#             print(input_name)\n",
    "#             print(output)\n",
    "            inputs[input_name] = output\n",
    "        # need to add here ar input, but taken from the original H - this is known, so why use the model output!\n",
    "#         inputs['H_ar'] = random_examples['H_ar'][j,i]\n",
    "        outputs_pred.append(np.squeeze(decoded))\n",
    "    pred.append(outputs_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find axis that corresponds to velocity\n",
    "v_index = np.where(np.array(decoder.output_names) == 'V_out')[0][0]\n",
    "print('v_index:', v_index)\n",
    "print('predictions shape:', np.array(pred).shape)\n",
    "model_datas_pred = copy.deepcopy(model_datas)\n",
    "model_datas_pred['V'].data[idx,...] = np.array(pred)[:,:,v_index,:]\n",
    "for i in idx:\n",
    "    pm_original = data.examples2pm(model_datas, i)\n",
    "    pm_pred = data.examples2pm(model_datas_pred, i)\n",
    "    pm_original.write(f'experiments/run_{run}/ex{i}original.mid')\n",
    "    pm_pred.write(f'experiments/run_{run}/ex{i}prediction.mid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hierarchical and/or Variational Prediction Attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = 216\n",
    "client = pymongo.MongoClient()  # assuming a local MongoDB\n",
    "fs = gridfs.GridFS(client.sacred)  # assuming database name is 'sacred'\n",
    "runs = client.sacred.runs\n",
    "# Now get run from the database\n",
    "run_entry = runs.find_one({'_id': run})\n",
    "config = run_entry['config']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_datas, seconds = data.folder2examples('training_data/midi_val', sparse=False, use_base_key=True, beats_per_ex=int(config['seq_length'] / 4), vel_cutoff=config['vel_cutoff'])\n",
    "model_datas_pred = copy.deepcopy(model_datas)\n",
    "\n",
    "random_examples, idx = data.n_rand_examples(model_datas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### predict using teacher forcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_input_reqs, model_output_reqs = models.get_model_reqs(**config)\n",
    "z, model_inputs = models.create_LSTMencoder_graph(model_input_reqs, **config)\n",
    "if config['variational']:\n",
    "    sampling_fn = models.sampling(**config)\n",
    "    z = layers.Lambda(sampling_fn)(z)\n",
    "\n",
    "# a few other \n",
    "config['stateful'] = False\n",
    "config['ar_inc_batch_shape'] = False\n",
    "# config['batch_size'] = 1\n",
    "\n",
    "if config['variational']:\n",
    "    sampling_fn = models.sampling(config['batch_size'], epsilon_std=config['epsilon_std'])\n",
    "    # z_input is the tensor that will be passed into the decoder\n",
    "    z_input = layers.Lambda(sampling_fn)(z)\n",
    "\n",
    "else:\n",
    "    z_input = z\n",
    "\n",
    "if config['hierarchical']:\n",
    "    build_decoder_graph = models.create_hierarchical_decoder_graph\n",
    "else:\n",
    "    build_decoder_graph =models.create_LSTMdecoder_graph_ar\n",
    "\n",
    "if config['variational']:\n",
    "pred, ar_inputs = models.build_decoder_graph(z, model_output_reqs, **config)\n",
    "autoencoder = tf.keras.Model(inputs=model_inputs + ar_inputs, outputs=pred, name=f'autoencoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.load_weights_safe(autoencoder, f'experiments/run_{run}/{run}_best_val_weights.hdf5', by_name=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For non teacher forced prediction, there might be trouble with layer names. We can address this be saving weights from the autoencoder we just made - that newly saved version should have updated layer names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = autoencoder.predict(random_examples)\n",
    "# find axis that corresponds to velocity\n",
    "v_index = np.where(np.array(autoencoder.output_names) == 'V_out')[0][0]\n",
    "print('velocity index:', v_index)\n",
    "model_datas_pred = copy.deepcopy(model_datas)\n",
    "model_datas_pred['V'].data[idx,...] = np.array(pred)[v_index,:,:,:]\n",
    "for i in idx:\n",
    "    pm_original = data.examples2pm(model_datas, i)\n",
    "    pm_pred = data.examples2pm(model_datas_pred, i)\n",
    "    pm_original.write(f'experiments/run_{run}/ex{i}original.mid')\n",
    "    pm_pred.write(f'experiments/run_{run}/ex{i}prediction_teacher_forced.mid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### predict the hard way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_input_reqs, model_output_reqs = models.get_model_reqs(**config)\n",
    "z, model_inputs = models.create_LSTMencoder_graph(model_input_reqs, **config)\n",
    "if config['variational']:\n",
    "    sampling_fn = models.sampling(**config)\n",
    "    z = layers.Lambda(sampling_fn)(z)\n",
    "\n",
    "config['stateful'] = True\n",
    "config['ar_inc_batch_shape'] = True\n",
    "config['batch_size'] = 1\n",
    "if config['hierarchical']:\n",
    "    conductor_out, ar_inputs, decoder = models.create_hierarchical_decoder_graph(z, model_output_reqs, **config)\n",
    "else:\n",
    "    pred, ar_inputs = models.create_LSTMdecoder_graph_ar(z, model_output_reqs, **config)\n",
    "autoconductor = tf.keras.Model(inputs=[model_inputs, ar_inputs], outputs=conductor_out, name=f'autoconductor')\n",
    "# autoconductor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load some weights\n",
    "models.load_weights_safe(autoconductor, f'experiments/run_{run}/{run}_best_train_weights.hdf5')\n",
    "models.load_weights_safe(decoder, f'experiments/run_{run}/{run}_best_train_weights.hdf5')\n",
    "# pred = autoencoder.predict(random_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_conductor_outs = autoconductor.predict(random_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conductor_substeps = int(config['seq_length'] / config['conductor_steps'])\n",
    "\n",
    "# predict on z\n",
    "pred = []\n",
    "inputs = {}\n",
    "# get required ar inputs from model datas - these are just zeros\n",
    "for out in model_output_reqs:\n",
    "    if out.seq:\n",
    "        inputs[out.name + '_ar'] = np.zeros((1,1,out.dim))\n",
    "print([f'{name}: {md_in.shape}' for name, md_in in inputs.items()])\n",
    "\n",
    "# What will unavailable for prediction?\n",
    "non_accessible = []\n",
    "\n",
    "filter_ar_pos = False # whether to set all ar inputs to zero for positions with no notes \n",
    "for i, auto_out in enumerate(zip(*auto_conductor_outs)):\n",
    "    print(f'Example {i + 1} of {len(idx)}')\n",
    "    decoder.reset_states()\n",
    "    outputs_pred = []\n",
    "    # iterate over timesteps\n",
    "    for c_step in range(config['conductor_steps']):\n",
    "        for c_substep in range(conductor_substeps):\n",
    "            t = c_step * conductor_substeps + c_substep\n",
    "            if c_substep == 0:\n",
    "                # get conductor output\n",
    "                inputs['c_in'] = np.expand_dims(np.expand_dims(auto_out[0][c_step], 0), 0)\n",
    "                # set initial states of decoder LSTMs\n",
    "                for k in range(config['decoder_lstms']):\n",
    "                    tf.keras.backend.set_value(decoder.get_layer(f'final_dec_LSTM_{k}').states[0], np.expand_dims(auto_out[k*2 + 1][c_step], 0))\n",
    "                    tf.keras.backend.set_value(decoder.get_layer(f'final_dec_LSTM_{k}').states[1], np.expand_dims(auto_out[k*2 + 2][c_step], 0))\n",
    "            # get the ar inputs\n",
    "            for out in model_output_reqs:\n",
    "                # will only be ar inputs if seq is true\n",
    "                # in practice, not all seq inputs might be required by the model - but the model will select these by name if they are all passed\n",
    "                if out.seq and out.name not in non_accessible:\n",
    "                    # need to expand dims - it is still seq data, just with time step of one\n",
    "                    inputs[out.name + '_ar'] = np.expand_dims(np.expand_dims(random_examples[out.name + '_ar'][i,t], 0), 0)\n",
    "            decoded = decoder.predict(inputs)\n",
    "            # iterate over outputs - feed put them into inputs\n",
    "            # ignores whether the model actually needs them all autoregressively!\n",
    "            for output_name, output in zip(decoder.output_names, decoded):\n",
    "                input_name = output_name.split('_')[0] + '_ar'\n",
    "                if filter_ar_pos:\n",
    "                    # set positions where there are no notes to zero\n",
    "                    # this assumes that all outputs have same dimensions as H! i.e., 88\n",
    "                    output[...,np.where(random_examples['H_in'][i,t] != 1)[0]] = 0\n",
    "                    inputs[input_name] = np.squeeze(output, 0)\n",
    "                else:\n",
    "                    inputs[input_name] = np.squeeze(output, 0)\n",
    "            outputs_pred.append(np.squeeze(decoded))\n",
    "    pred.append(outputs_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(32):\n",
    "    print(min(np.array(pred)[0,t,v_index,:]), max(np.array(pred)[0,t,v_index,:]) - min(np.array(pred)[0,t,v_index,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find axis that corresponds to velocity\n",
    "v_index = np.where(np.array(decoder.output_names) == 'V_unconcat')[0][0]\n",
    "print('v_index:', v_index)\n",
    "print('predictions shape:', np.array(pred).shape)\n",
    "model_datas_pred = copy.deepcopy(model_datas)\n",
    "model_datas_pred['V'].data[idx,...] = np.array(pred)[:,:,v_index,:]\n",
    "for i in idx:\n",
    "    pm_original = data.examples2pm(model_datas, i)\n",
    "    pm_pred = data.examples2pm(model_datas_pred, i)\n",
    "    pm_original.write(f'experiments/run_{run}/ex{i}original.mid')\n",
    "    pm_pred.write(f'experiments/run_{run}/run_{run}_ex{i}prediction.mid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Various mongodb operations\n",
    "Code left over from doing a few things with the sacred mongodb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bson.objectid import ObjectId\n",
    "client = pymongo.MongoClient()  # assuming a local MongoDB\n",
    "fs = gridfs.GridFS(client.sacred)  # assuming database name is 'sacred'\n",
    "\n",
    "runs = client.sacred.runs\n",
    "metrics = client.sacred.metrics\n",
    "# Now get run from the database\n",
    "run_entry = runs.find_one({'_id': 212})\n",
    "metric_ids = {m['name']: ObjectId(m['id']) for m in run_entry['info']['metrics']}\n",
    "# metrics_entry = metrics.find_one({'_id': metric_ids['V_out_categorical_crossentropy']})\n",
    "\n",
    "# can always get weights like this, but need to write them to a temp file before loading\n",
    "# weights = fs.get(run_entry['artifacts'][0]['file_id']).read()\n",
    "print(run_entry.keys())\n",
    "sizeof_fmt(sys.getsizeof(apply_backspaces_and_linefeeds(run_entry['captured_out'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import ast\n",
    "for run_id in [140, 146, 171]:\n",
    "    run_entry = runs.find_one({'_id': run_id})\n",
    "    metric_ids = {m['name']: ObjectId(m['id']) for m in run_entry['info']['metrics']}\n",
    "\n",
    "    epochs = run_entry['config']['epochs']\n",
    "    with open(f'experiments/run_{run_id}/history-{epochs}epochs.json', 'rb') as f:\n",
    "        hist = json.load(f)\n",
    "        hist = ast.literal_eval(hist)\n",
    "\n",
    "    metric_ids = {m['name']: ObjectId(m['id']) for m in run_entry['info']['metrics']}\n",
    "    delta = (metrics_entry['timestamps'][-1] - metrics_entry['timestamps'][-2])\n",
    "    timestamps = metrics_entry['timestamps']\n",
    "    recorded_epochs = len(timestamps)\n",
    "    # generate new timestamps\n",
    "    timestamps_new = metrics_entry['timestamps'] + [timestamps[-1] + i * delta for i in range(1, epochs - recorded_epochs + 1)]\n",
    "\n",
    "\n",
    "\n",
    "    for k, v in hist.items():\n",
    "        metrics_entry = metrics.find_one({'_id': metric_ids[k]})\n",
    "        if not metrics_entry is None:\n",
    "            # get delta and new timesteps\n",
    "            delta = (metrics_entry['timestamps'][-1] - metrics_entry['timestamps'][-2])\n",
    "            timestamps = metrics_entry['timestamps']\n",
    "            recorded_epochs = len(timestamps)\n",
    "            # generate new timestamps\n",
    "            timestamps_new = metrics_entry['timestamps'] + [timestamps[-1] + i * delta for i in range(1, epochs - recorded_epochs + 1)]\n",
    "            agreement = sum([(a - b) < 0.00001 for a, b in zip(v[:10], metrics_entry['values'][:10])])\n",
    "            if agreement == 10:\n",
    "                metrics.update_one({'_id': metric_ids[k]}, {\n",
    "                  '$set': {\n",
    "                    'timestamps': timestamps_new, 'steps': [i for i in range(epochs)], 'values': v\n",
    "                  }}\n",
    "                    )\n",
    "            else:\n",
    "                print(f'problem with {k}')\n",
    "                print('agreement:', agreement)\n",
    "\n",
    "\n",
    "    \n",
    "# metrics_entry['timestamps'][-1] + 2 * (metrics_entry['timestamps'][-1] - metrics_entry['timestamps'][-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_entries = runs.find({'_id': {'$lt': 216}})\n",
    "for run in run_entries:\n",
    "    print('processing run', run['_id'])\n",
    "    c_out_filtered = '\\n'.join([s for s in apply_backspaces_and_linefeeds(run['captured_out']).split('\\n') if '>.' not in s and '....' not in s and s != ''])\n",
    "    runs.update_one({'_id': run['_id']}, {\n",
    "      '$set': {\n",
    "        'captured_out': c_out_filtered\n",
    "      }}\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_entries = runs.find({'_id': {'$lt': 221, '$gt': 216}})\n",
    "for run in run_entries:\n",
    "    print(run['_id'])\n",
    "    print(run['captured_out'][:120])\n",
    "    print(sizeof_fmt(sys.getsizeof(run['captured_out'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_entries = runs.find({'_id': {'$lt': 221, '$gt': 216}})\n",
    "for run in run_entries:\n",
    "    print(run['_id'])\n",
    "    print(run['captured_out'][:120])\n",
    "    print(sizeof_fmt(sys.getsizeof(run['captured_out'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_entry = runs.find_one({'_id': {'$lt': 221}})\n",
    "# use set for setting fields. unset removes fields.\n",
    "# This example finds runs with id <= 146, with field config.z_activation, and updates the field to relu\n",
    "runs.update_many({'_id': {'$lte': 146}, 'config.z_activation': {'$exists': True}}, {\n",
    "  '$set': {\n",
    "    'config.z_activation': 'relu'\n",
    "  }}\n",
    "    )\n",
    "# print(runs.find_one({'_id': 146})['config']['z_activation'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
