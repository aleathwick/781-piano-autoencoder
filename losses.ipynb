{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import pymongo\n",
    "import gridfs\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "from scipy.sparse import csc_matrix, csr_matrix\n",
    "import pickle\n",
    "import pretty_midi\n",
    "import sys\n",
    "import copy\n",
    "from collections import namedtuple\n",
    "import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "from IPython.display import clear_output\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'src.losses' from '/storage/781-piano-autoencoder/src/losses.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import modules, including a reload statement so that they can be reimported after a change to the methods \n",
    "import src.midi_utils as midi_utils\n",
    "reload(midi_utils)\n",
    "\n",
    "import src.data as data\n",
    "reload(data)\n",
    "\n",
    "import src.models as models\n",
    "reload(models)\n",
    "\n",
    "import src.ml_classes as ml_classes\n",
    "reload(ml_classes)\n",
    "\n",
    "import src.exp_utils as exp_utils\n",
    "reload(exp_utils)\n",
    "\n",
    "import src.losses as losses\n",
    "reload(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = 307\n",
    "client = pymongo.MongoClient()  # assuming a local MongoDB\n",
    "fs = gridfs.GridFS(client.sacred)  # assuming database name is 'sacred'\n",
    "runs = client.sacred.runs\n",
    "# Now get run from the database\n",
    "run_entry = runs.find_one({'_id': run})\n",
    "config = run_entry['config']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 230/230 [01:13<00:00,  3.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10h 47m 55s of data\n",
      "created model data H :    (32, 88) data shape,     4122 training examples\n",
      "created model data O :    (32, 88) data shape,     4122 training examples\n",
      "created model data V :    (32, 88) data shape,     4122 training examples\n",
      "created model data R :    (32, 88) data shape,     4122 training examples\n",
      "created model data S :    (32, 2) data shape,     4122 training examples\n",
      "created model data key :    (12,) data shape,     4122 training examples\n",
      "created model data tempo :    (1,) data shape,     4122 training examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 1/12 [00:00<00:01,  7.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created model data V_mean :    (1,) data shape,     4122 training examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:03<00:00,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00h 38m 48s of data\n",
      "created model data H :    (32, 88) data shape,     250 training examples\n",
      "created model data O :    (32, 88) data shape,     250 training examples\n",
      "created model data V :    (32, 88) data shape,     250 training examples\n",
      "created model data R :    (32, 88) data shape,     250 training examples\n",
      "created model data S :    (32, 2) data shape,     250 training examples\n",
      "created model data key :    (12,) data shape,     250 training examples\n",
      "created model data tempo :    (1,) data shape,     250 training examples\n",
      "created model data V_mean :    (1,) data shape,     250 training examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# get training data\n",
    "model_datas_train, seconds1 = data.folder2examples('training_data/midi_train' + config['data_folder_prefix'], sparse=False,\n",
    "                                                  use_base_key=config['use_base_key'], beats_per_ex=int(config['seq_length'] / config['sub_beats']),\n",
    "                                                  nth_file=None, vel_cutoff=config['vel_cutoff'], sub_beats=config['sub_beats'])\n",
    "model_datas_val, seconds2 = data.folder2examples('training_data/midi_val' + config['data_folder_prefix'], sparse=False,\n",
    "                                                use_base_key=config['use_base_key'], beats_per_ex=int(config['seq_length'] / config['sub_beats']),\n",
    "                                                sub_beats=config['sub_beats'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6467469894731687"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seconds2 / 3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_input_reqs, model_output_reqs = models.get_model_reqs(config['model_inputs'], config['model_outputs'])\n",
    "\n",
    "config['beta_rate'] = 0\n",
    "\n",
    "# model kwargs - for the encoder/decoder builder functions, make a dictionary to pass as kwargs\n",
    "model_kwargs = config\n",
    "# if variational, z will be a list of [[means], [stds]]\n",
    "build_encoder_graph = models.create_LSTMencoder_graph\n",
    "z, model_inputs_tf = build_encoder_graph(model_input_reqs, **model_kwargs)\n",
    "\n",
    "if config['variational']:\n",
    "    beta_fn = exp_utils.beta_fn2(config['beta_rate'], config['max_beta'])\n",
    "    loss_for_train, beta_cb = losses.vae_custom_loss(z, beta_fn, free_bits=config['free_bits'], kl_weight=config['kl_weight'])\n",
    "    sampling_fn = models.sampling(config['batch_size'], epsilon_std=config['epsilon_std'])\n",
    "    # z_input is the tensor that will be passed into the decoder\n",
    "    z_input = layers.Lambda(sampling_fn)(z)\n",
    "else:\n",
    "    loss_for_train = config['loss']\n",
    "    z_input = z\n",
    "\n",
    "if config['hierarchical']:\n",
    "    build_decoder_graph = models.create_hierarchical_decoder_graph\n",
    "else:\n",
    "    build_decoder_graph =models.create_LSTMdecoder_graph_ar\n",
    "\n",
    "pred, ar_inputs_tf = build_decoder_graph(z_input, model_output_reqs, **model_kwargs)\n",
    "autoencoder = tf.keras.Model(inputs=model_inputs_tf + ar_inputs_tf, outputs=pred, name=f'autoencoder')\n",
    "autoencoder.summary()\n",
    "\n",
    "\n",
    "dg = ml_classes.ModelDataGenerator([md for md in model_datas_train.values()],\n",
    "                                    [model_in.name for model_in in model_input_reqs],\n",
    "                                    [model_out.name for model_out in model_output_reqs],\n",
    "                                    t_force=True, batch_size = config['batch_size'], seq_length=config['seq_length'])\n",
    "\n",
    "dg_val = ml_classes.ModelDataGenerator([md for md in model_datas_val.values()],\n",
    "                                    [model_in.name for model_in in model_input_reqs],\n",
    "                                    [model_out.name for model_out in model_output_reqs],\n",
    "                                    t_force=True, batch_size = config['batch_size'], seq_length=config['seq_length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config\n",
    "# config['loss_weights'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam()\n",
    "autoencoder.compile(optimizer=opt, loss=loss_for_train, metrics=config['metrics'], loss_weights=config['loss_weights'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoencoder.load_weights(f'experiments/run_{run}/{run}_best_train_weights.hdf5', by_name=True)\n",
    "models.load_weights_safe(autoencoder,f'experiments/run_{run}/{run}_best_val_weights.hdf5',by_name=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_examples, idx = data.n_rand_examples(model_datas_val, n=64)\n",
    "random_examples['H_out'] = random_examples['H_ar']\n",
    "random_examples['V_out'] = random_examples['V_ar']\n",
    "autoencoder.evaluate(random_examples, random_examples, batch_size=config['batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrices2note_tuples(H, V):\n",
    "    \"\"\"given an example in HOV form, return note_tuples and velocities for notes\n",
    "    \n",
    "    Notes:\n",
    "    experimental function... It is easier to just go straight to note_tuple like representation from pm.\n",
    "    Won't use this one.\n",
    "    \"\"\"\n",
    "    # this is in order: pitch from low to high for first beat, then for second...\n",
    "    # note mask for selecting note positions\n",
    "    note_mask = np.where(H != 0)\n",
    "    # list of lists, each sublist is [pitch, timestep]\n",
    "    note_tuples = [[pitch, timestep] for timestep, pitch in zip(note_mask[0], note_mask[1])]\n",
    "    velocities = V[note_mask]\n",
    "    return note_tuples, velocities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get training data\n",
    "beats_per_ex = 16\n",
    "sub_beats = 2\n",
    "seq_length = beats_per_ex * sub_beats\n",
    "model_datas_train, seconds = data.folder2examples('training_data/midi_train' + '_8', sparse=False,\n",
    "                                                  beats_per_ex=beats_per_ex, nth_file=8, vel_cutoff=4, sub_beats=sub_beats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = []\n",
    "for i in range(len(model_datas_train['H'].data)):\n",
    "    a, b = matrices2note_tuples(model_datas_train['H'].data[i], model_datas_train['V'].data[i])\n",
    "    lengths.append(len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(lengths, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_beat_len = .46\n",
    "# time of note is closest to 5th subbeat\n",
    "time = 5.3 * sub_beat_len\n",
    "round(time / sub_beat_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.instruments[0].notes[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing model data generator for V_no_zeros\n",
    "model_input_reqs, model_output_reqs = models.get_model_reqs(config['model_inputs'], config['model_outputs'])\n",
    "dg = ml_classes.ModelDataGenerator([md for md in model_datas_train.values()],\n",
    "                                    [model_in.name for model_in in model_input_reqs],\n",
    "                                    [model_out.name for model_out in model_output_reqs],\n",
    "                                    t_force=True, batch_size = config['batch_size'], seq_length=config['seq_length'],\n",
    "                                    V_no_zeros=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.000879660931373523,\n",
       " 0.0014481468824669719,\n",
       " 0.001141855726018548,\n",
       " 0.0008663543849252164,\n",
       " 0.001760462997481227,\n",
       " 0.0023947665467858315]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat = 'loss'\n",
    "\n",
    "# [[step for step in run['info']['logs'][stat]] for run in run_entries]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examining hyperparameters: plotting metrics from different training runs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### set up\n",
    "id_list = [i for i in range(389, 395)] + [387] # runs of interest\n",
    "x = 'recurrent_dropout' # hyperparameter of interest - will be plotted on x axis\n",
    "# the parameter might be a list\n",
    "parameter_is_list = False\n",
    "index_of_interest = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "### set up\n",
    "id_list = [i for i in range(372, 380)] # runs of interest\n",
    "x = 'hidden_state' # hyperparameter of interest - will be plotted on x axis\n",
    "# the parameter might be a list\n",
    "parameter_is_list = False\n",
    "index_of_interest = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "### set up\n",
    "id_list = [i for i in range(405, 417)] # runs of interest\n",
    "x = 'hidden_state' # hyperparameter of interest - will be plotted on x axis\n",
    "# the parameter might be a list\n",
    "parameter_is_list = False\n",
    "index_of_interest = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7f1f24edb2c498da7de72cd892b6bad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Checkbox(value=False, description='loss'), Checkbox(value=False, description='mse'), Checkbox(v…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# establish connection to database\n",
    "client = pymongo.MongoClient()\n",
    "fs = gridfs.GridFS(client.sacred)\n",
    "runs = client.sacred.runs\n",
    "metrics = client.sacred.metrics\n",
    "\n",
    "# determine which runs are needed\n",
    "run_entries = list(runs.find({'_id': {'$in': id_list}}))\n",
    "# metric_ids = {m['name']: ObjectId(m['id']) for m in run_entry['info']['metrics']}\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# What is the hyperparameter of interst? (x axis)\n",
    "df[x] = [run['config'][x] for run in run_entries]\n",
    "# change index to reflect run id\n",
    "df.index = [run['_id'] for run in run_entries]\n",
    "\n",
    "if parameter_is_list:\n",
    "    df[x] = df[x].apply(lambda x: x[index_of_interest])\n",
    "\n",
    "# stats where minimum is best, or maximum is best\n",
    "min_stats = [k for k in run_entries[0]['info']['logs'].keys() if any(x in k for x in ['categ', 'loss', 'mse'])]\n",
    "max_stats = [k for k in run_entries[0]['info']['logs'].keys() if any(x in k for x in ['acc'])]\n",
    "\n",
    "for stat in min_stats:\n",
    "#     df[stat] = [min([step['value'] for step in run['info']['logs'][stat]]) for run in run_entries]\n",
    "    # for some inexplicable reason, sometimes the entry is a list of values, rather than a list of dictionaries with dtype recorded\n",
    "    df[stat] = [min([step['value'] for step in run['info']['logs'][stat]]) if isinstance(run['info']['logs'][stat][-1], dict) else min(run['info']['logs'][stat]) for run in run_entries]\n",
    "for stat in max_stats:\n",
    "    df[stat] =[max([step['value'] for step in run['info']['logs'][stat]]) if isinstance(run['info']['logs'][stat][-1], dict) else max(run['info']['logs'][stat]) for run in run_entries]\n",
    "\n",
    "### simple checkbox gui\n",
    "# one checkbox per metric\n",
    "checkboxes = [widgets.Checkbox(description=col,) for col in df.columns if col != x]\n",
    "# plot button\n",
    "plot_button = widgets.Button(description='Plot',button_style='success')\n",
    "# button_style one of 'success', 'info', 'warning', 'danger' or ''\n",
    "log_buttons = [widgets.ToggleButton(description=f'log {i} axis', button_style='info') for i in ['x', 'y']]\n",
    "# output of plotting\n",
    "out = widgets.Output()\n",
    "def on_button_click(_):\n",
    "    \"\"\"function for plotting ticked metrics on button click\"\"\"\n",
    "    with out:\n",
    "        # don't neglect to clear the output!\n",
    "        clear_output()\n",
    "        plot_metrics = [c.description for c in checkboxes if c.value]\n",
    "        for m in plot_metrics:\n",
    "            plt.plot(df.sort_values(x)[x], df.sort_values(x)[m], marker='o')\n",
    "        if log_buttons[0].value:\n",
    "            plt.xscale('log')\n",
    "        if log_buttons[1].value:\n",
    "            plt.yscale('log')\n",
    "        plt.xlabel(x)\n",
    "        plt.legend(plot_metrics, loc='lower center')\n",
    "        # set x labels\n",
    "#         plt.xticks(plt.xticks()[0], [''] + [f'{j:.2f}' + '\\n' + str(i) for i, j in sorted(zip(df.index, df[x]), key=lambda x: x[1])])\n",
    "#         plt.xticks(plt.xticks()[0], [''] + [f'{j:.2f}' + '\\n' + str(i) for i, j in sorted(zip(df.index, df[x]), key=lambda x: x[1])])\n",
    "#         ticks = sorted([(tick, label) for tick, label in zip(list(plt.xticks()[0]) + df[x].to_list(), [list(plt.xticks()[0])] +  df.index.to_list())])\n",
    "        plt.xticks([t for t, _ in ticks], [l for _, l in ticks])\n",
    "        print([t.get_label() for t in plt.xticks()[1]])\n",
    "        labels = df.index\n",
    "        plt.show()\n",
    "        # sort and print run numbers according to order they appear in plot\n",
    "        print([run for _, run in sorted(zip(df[x], df.index))])\n",
    "    \n",
    "# linking button and function together using a button's method\n",
    "plot_button.on_click(on_button_click)\n",
    "# displaying button and its output together\n",
    "widgets.VBox(checkboxes + log_buttons + [plot_button,out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hidden_state</th>\n",
       "      <th>loss</th>\n",
       "      <th>mse</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_mse</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>model_inputs</th>\n",
       "      <th>bi_encoder_lstms</th>\n",
       "      <th>uni_encoder_lstms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>2</td>\n",
       "      <td>0.007591</td>\n",
       "      <td>0.007591</td>\n",
       "      <td>0.006967</td>\n",
       "      <td>0.006967</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64</td>\n",
       "      <td>[PCn, PSn, TBn, TSBn]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>3</td>\n",
       "      <td>0.007151</td>\n",
       "      <td>0.007151</td>\n",
       "      <td>0.006712</td>\n",
       "      <td>0.006712</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64</td>\n",
       "      <td>[PCn, PSn, TBn, TSBn]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>4</td>\n",
       "      <td>0.006655</td>\n",
       "      <td>0.006655</td>\n",
       "      <td>0.006222</td>\n",
       "      <td>0.006222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64</td>\n",
       "      <td>[PCn, PSn, TBn, TSBn]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>5</td>\n",
       "      <td>0.006475</td>\n",
       "      <td>0.006475</td>\n",
       "      <td>0.006049</td>\n",
       "      <td>0.006049</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64</td>\n",
       "      <td>[PCn, PSn, TBn, TSBn]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>6</td>\n",
       "      <td>0.006311</td>\n",
       "      <td>0.006311</td>\n",
       "      <td>0.005794</td>\n",
       "      <td>0.005794</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64</td>\n",
       "      <td>[PCn, PSn, TBn, TSBn]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>7</td>\n",
       "      <td>0.005877</td>\n",
       "      <td>0.005877</td>\n",
       "      <td>0.005739</td>\n",
       "      <td>0.005739</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64</td>\n",
       "      <td>[PCn, PSn, TBn, TSBn]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>12</td>\n",
       "      <td>0.005372</td>\n",
       "      <td>0.005372</td>\n",
       "      <td>0.005534</td>\n",
       "      <td>0.005534</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64</td>\n",
       "      <td>[PCn, PSn, TBn, TSBn]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>24</td>\n",
       "      <td>0.004857</td>\n",
       "      <td>0.004857</td>\n",
       "      <td>0.005303</td>\n",
       "      <td>0.005303</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64</td>\n",
       "      <td>[PCn, PSn, TBn, TSBn]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>48</td>\n",
       "      <td>0.003463</td>\n",
       "      <td>0.003463</td>\n",
       "      <td>0.005487</td>\n",
       "      <td>0.005487</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64</td>\n",
       "      <td>[PCn, PSn, TBn, TSBn]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     hidden_state      loss       mse  val_loss   val_mse  accuracy  \\\n",
       "405             2  0.007591  0.007591  0.006967  0.006967       0.0   \n",
       "406             3  0.007151  0.007151  0.006712  0.006712       0.0   \n",
       "407             4  0.006655  0.006655  0.006222  0.006222       0.0   \n",
       "408             5  0.006475  0.006475  0.006049  0.006049       0.0   \n",
       "409             6  0.006311  0.006311  0.005794  0.005794       0.0   \n",
       "410             7  0.005877  0.005877  0.005739  0.005739       0.0   \n",
       "414            12  0.005372  0.005372  0.005534  0.005534       0.0   \n",
       "415            24  0.004857  0.004857  0.005303  0.005303       0.0   \n",
       "416            48  0.003463  0.003463  0.005487  0.005487       0.0   \n",
       "\n",
       "     val_accuracy  batch_size           model_inputs  bi_encoder_lstms  \\\n",
       "405           0.0          64  [PCn, PSn, TBn, TSBn]                 1   \n",
       "406           0.0          64  [PCn, PSn, TBn, TSBn]                 1   \n",
       "407           0.0          64  [PCn, PSn, TBn, TSBn]                 1   \n",
       "408           0.0          64  [PCn, PSn, TBn, TSBn]                 1   \n",
       "409           0.0          64  [PCn, PSn, TBn, TSBn]                 1   \n",
       "410           0.0          64  [PCn, PSn, TBn, TSBn]                 1   \n",
       "414           0.0          64  [PCn, PSn, TBn, TSBn]                 1   \n",
       "415           0.0          64  [PCn, PSn, TBn, TSBn]                 1   \n",
       "416           0.0          64  [PCn, PSn, TBn, TSBn]                 1   \n",
       "\n",
       "     uni_encoder_lstms  \n",
       "405                  1  \n",
       "406                  1  \n",
       "407                  1  \n",
       "408                  1  \n",
       "409                  1  \n",
       "410                  1  \n",
       "414                  1  \n",
       "415                  1  \n",
       "416                  1  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misc_params = ['hidden_state',  'batch_size', 'model_inputs', 'bi_encoder_lstms', 'uni_encoder_lstms']\n",
    "# misc_params = set([key for run in run_entries for key in run['config'].keys()])\n",
    "for param in misc_params:\n",
    "    df[param] = [run['config'][param] for run in run_entries]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 4, 5, 6, 7, 12, 24, 48]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[x].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xticks()[1][1].get_label()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
