{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import pymongo\n",
    "import gridfs\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "from scipy.sparse import csc_matrix, csr_matrix\n",
    "import pickle\n",
    "import pretty_midi\n",
    "import sys\n",
    "import copy\n",
    "from collections import namedtuple\n",
    "import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'src.losses' from '/storage/781-piano-autoencoder/src/losses.py'>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import modules, including a reload statement so that they can be reimported after a change to the methods \n",
    "import src.midi_utils as midi_utils\n",
    "reload(midi_utils)\n",
    "\n",
    "import src.data as data\n",
    "reload(data)\n",
    "\n",
    "import src.models as models\n",
    "reload(models)\n",
    "\n",
    "import src.ml_classes as ml_classes\n",
    "reload(ml_classes)\n",
    "\n",
    "import src.exp_utils as exp_utils\n",
    "reload(exp_utils)\n",
    "\n",
    "import src.losses as losses\n",
    "reload(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = 307\n",
    "client = pymongo.MongoClient()  # assuming a local MongoDB\n",
    "fs = gridfs.GridFS(client.sacred)  # assuming database name is 'sacred'\n",
    "runs = client.sacred.runs\n",
    "# Now get run from the database\n",
    "run_entry = runs.find_one({'_id': run})\n",
    "config = run_entry['config']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:07<00:00,  2.23it/s]\n",
      "  8%|▊         | 1/12 [00:00<00:01,  6.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01h 00m 07s of data\n",
      "created model data H :    (32, 88) data shape,     380 training examples\n",
      "created model data O :    (32, 88) data shape,     380 training examples\n",
      "created model data V :    (32, 88) data shape,     380 training examples\n",
      "created model data R :    (32, 88) data shape,     380 training examples\n",
      "created model data S :    (32, 2) data shape,     380 training examples\n",
      "created model data key :    (12,) data shape,     380 training examples\n",
      "created model data tempo :    (1,) data shape,     380 training examples\n",
      "created model data V_mean :    (1,) data shape,     380 training examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:04<00:00,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00h 38m 48s of data\n",
      "created model data H :    (32, 88) data shape,     250 training examples\n",
      "created model data O :    (32, 88) data shape,     250 training examples\n",
      "created model data V :    (32, 88) data shape,     250 training examples\n",
      "created model data R :    (32, 88) data shape,     250 training examples\n",
      "created model data S :    (32, 2) data shape,     250 training examples\n",
      "created model data key :    (12,) data shape,     250 training examples\n",
      "created model data tempo :    (1,) data shape,     250 training examples\n",
      "created model data V_mean :    (1,) data shape,     250 training examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# get training data\n",
    "model_datas_train, seconds = data.folder2examples('training_data/midi_train' + config['data_folder_prefix'], sparse=True,\n",
    "                                                  use_base_key=config['use_base_key'], beats_per_ex=int(config['seq_length'] / config['sub_beats']),\n",
    "                                                  nth_file=10, vel_cutoff=config['vel_cutoff'], sub_beats=config['sub_beats'])\n",
    "model_datas_val, seconds = data.folder2examples('training_data/midi_val' + config['data_folder_prefix'], sparse=True,\n",
    "                                                use_base_key=config['use_base_key'], beats_per_ex=int(config['seq_length'] / config['sub_beats']),\n",
    "                                                sub_beats=config['sub_beats'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"autoencoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "V_mean_in (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "H_in (InputLayer)               [(None, 32, 88)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "repeat32Times (RepeatVector)    (None, 32, 1)        0           V_mean_in[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "joinModelInput (Concatenate)    (None, 32, 89)       0           H_in[0][0]                       \n",
      "                                                                 repeat32Times[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bi_enc_lstm_0 (Bidirectional)   (None, 32, 2048)     9125888     joinModelInput[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bi_enc_lstm_1 (Bidirectional)   (None, 32, 2048)     25174016    bi_enc_lstm_0[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bi_enc_lstm_2 (Bidirectional)   (None, 2048)         25174016    bi_enc_lstm_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "enc_dense_0 (Dense)             (None, 1024)         2098176     bi_enc_lstm_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "z_mean (Dense)                  (None, 512)          524800      enc_dense_0[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "z_log_sigma (Dense)             (None, 512)          524800      enc_dense_0[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (64, 512)            0           z_mean[0][0]                     \n",
      "                                                                 z_log_sigma[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "initial_dense (Dense)           (64, 1024)           525312      lambda_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_8 (RepeatVector)  (64, 32, 1024)       0           initial_dense[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lstm_h0_0 (Dense)               (64, 1024)           525312      lambda_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_c0_0 (Dense)               (64, 1024)           525312      lambda_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "H_ar (InputLayer)               [(None, 32, 88)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "V_ar (InputLayer)               [(None, 32, 88)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_lstm_0 (LSTM)               (64, 32, 1024)       8392704     repeat_vector_8[0][0]            \n",
      "                                                                 lstm_h0_0[0][0]                  \n",
      "                                                                 lstm_c0_0[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (64, 32, 1200)       0           H_ar[0][0]                       \n",
      "                                                                 V_ar[0][0]                       \n",
      "                                                                 dec_lstm_0[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lstm_h0_final (Dense)           (64, 1024)           525312      lambda_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_c0_final (Dense)           (64, 1024)           525312      lambda_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dec_lstm_final (LSTM)           (64, 32, 1024)       9113600     concatenate_8[0][0]              \n",
      "                                                                 lstm_h0_final[0][0]              \n",
      "                                                                 lstm_c0_final[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "H_out (TimeDistributed)         (64, 32, 88)         90200       dec_lstm_final[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "V_out (TimeDistributed)         (64, 32, 88)         90200       dec_lstm_final[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 82,934,960\n",
      "Trainable params: 82,934,960\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_input_reqs, model_output_reqs = models.get_model_reqs(config['model_inputs'], config['model_outputs'])\n",
    "\n",
    "config['beta_rate'] = 0\n",
    "\n",
    "# model kwargs - for the encoder/decoder builder functions, make a dictionary to pass as kwargs\n",
    "model_kwargs = config\n",
    "# if variational, z will be a list of [[means], [stds]]\n",
    "build_encoder_graph = models.create_LSTMencoder_graph\n",
    "z, model_inputs_tf = build_encoder_graph(model_input_reqs, **model_kwargs)\n",
    "\n",
    "if config['variational']:\n",
    "    beta_fn = exp_utils.beta_fn2(config['beta_rate'], config['max_beta'])\n",
    "    loss_for_train, beta_cb = losses.vae_custom_loss(z, beta_fn, free_bits=config['free_bits'], kl_weight=config['kl_weight'])\n",
    "    sampling_fn = models.sampling(config['batch_size'], epsilon_std=config['epsilon_std'])\n",
    "    # z_input is the tensor that will be passed into the decoder\n",
    "    z_input = layers.Lambda(sampling_fn)(z)\n",
    "\n",
    "else:\n",
    "    loss_for_train = config['loss']\n",
    "    z_input = z\n",
    "\n",
    "if config['hierarchical']:\n",
    "    build_decoder_graph = models.create_hierarchical_decoder_graph\n",
    "else:\n",
    "    build_decoder_graph =models.create_LSTMdecoder_graph_ar\n",
    "\n",
    "pred, ar_inputs_tf = build_decoder_graph(z_input, model_output_reqs, **model_kwargs)\n",
    "autoencoder = tf.keras.Model(inputs=model_inputs_tf + ar_inputs_tf, outputs=pred, name=f'autoencoder')\n",
    "autoencoder.summary()\n",
    "\n",
    "\n",
    "dg = ml_classes.ModelDataGenerator([md for md in model_datas_train.values()],\n",
    "                                    [model_in.name for model_in in model_input_reqs],\n",
    "                                    [model_out.name for model_out in model_output_reqs],\n",
    "                                    t_force=True, batch_size = config['batch_size'], seq_length=config['seq_length'])\n",
    "\n",
    "dg_val = ml_classes.ModelDataGenerator([md for md in model_datas_val.values()],\n",
    "                                    [model_in.name for model_in in model_input_reqs],\n",
    "                                    [model_out.name for model_out in model_output_reqs],\n",
    "                                    t_force=True, batch_size = config['batch_size'], seq_length=config['seq_length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam()\n",
    "autoencoder.compile(optimizer=opt, loss=loss_for_train, metrics=config['metrics'], loss_weights=config['loss_weights'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15.581132888793945,\n",
       " 7.763078,\n",
       " 2.606018,\n",
       " 0.0146484375,\n",
       " 7.763078,\n",
       " 0.011230469,\n",
       " 2.606018]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.evaluate(dg.__getitem__(0)[0], dg.__getitem__(0)[1], batch_size=config['batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# autoencoder.load_weights(f'experiments/run_{run}/{run}_best_train_weights.hdf5', by_name=True)\n",
    "models.load_weights_safe(autoencoder,f'experiments/run_{run}/{run}_best_val_weights.hdf5',by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[49.08544921875,\n",
       " 24.667273,\n",
       " 8.139393,\n",
       " 0.0009765625,\n",
       " 24.667273,\n",
       " 0.00048828125,\n",
       " 8.139393]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# much worse AFTER loading weights, for some odd reason... Something is being scrambled somewhere.\n",
    "autoencoder.evaluate(dg.__getitem__(0)[0], dg.__getitem__(0)[1], batch_size=config['batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_examples, idx = data.n_rand_examples(model_datas_val, n=64)\n",
    "random_examples['H_out'] = random_examples['H_ar']\n",
    "random_examples['V_out'] = random_examples['V_ar']\n",
    "autoencoder.evaluate(random_examples, random_examples, batch_size=config['batch_size'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
